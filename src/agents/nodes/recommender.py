"""
Recommender Node: Synthesizes investigations and retrieved context to generate final recommendations.
"""
import json
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from ..medical_diagnostic_graph import GraphState

class RecommenderNode:
    """
    Recommender Node: Synthesizes investigations and retrieved context.
    
    Waits for both InvestigationGenerator and DocumentRetriever to complete.
    """
    
    def __init__(self, gemini_model):
        """
        Initialize the Recommender node.
        
        Args:
            gemini_model: Configured Gemini model for text generation
        """
        self.gemini_model = gemini_model
    
    def __call__(self, state: "GraphState") -> "GraphState":
        """
        Execute the recommender logic.
        
        Args:
            state: Current graph state
            
        Returns:
            Updated graph state with final recommendations
        """
        print("ğŸ’¡ Recommender: Generating final recommendations...")
        
        diagnosis = state.get("diagnosis", {})
        risk_assessment = state.get("risk_assessment", {})
        investigation_plan = state.get("investigation_plan", [])
        retrieved_documents = state.get("retrieved_documents", [])
        
        try:
            # Build context
            context = f"""**Cháº©n Ä‘oÃ¡n:**
{json.dumps(diagnosis, ensure_ascii=False, indent=2)}

**ÄÃ¡nh giÃ¡ rá»§i ro:**
{json.dumps(risk_assessment, ensure_ascii=False, indent=2)}

**Káº¿ hoáº¡ch xÃ©t nghiá»‡m:**
{json.dumps(investigation_plan, ensure_ascii=False, indent=2)}

**TÃ i liá»‡u tham kháº£o:**
{len(retrieved_documents)} documents retrieved"""
            
            # Generate recommendations using Gemini
            recommendation_prompt = f"""Dá»±a trÃªn phÃ¢n tÃ­ch, Ä‘Æ°a ra khuyáº¿n nghá»‹ cuá»‘i cÃ¹ng cho bá»‡nh nhÃ¢n.

{context}

**Nhiá»‡m vá»¥:** Viáº¿t khuyáº¿n nghá»‹ hÃ nh Ä‘á»™ng rÃµ rÃ ng, dá»… hiá»ƒu (3-5 cÃ¢u).

Bao gá»“m:
1. HÃ nh Ä‘á»™ng ngay láº­p tá»©c (náº¿u cáº§n)
2. Khi nÃ o cáº§n gáº·p bÃ¡c sÄ©
3. XÃ©t nghiá»‡m cáº§n lÃ m
4. ChÄƒm sÃ³c táº¡i nhÃ  (náº¿u phÃ¹ há»£p)

**Khuyáº¿n nghá»‹ (tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n):**"""

            response = self.gemini_model.generate_content(recommendation_prompt)
            recommendation = response.text.strip()
            
            state["recommendation"] = recommendation
            state["final_response"] = self._format_final_response(state)
            state["messages"].append("âœ… Recommender: Final recommendations generated")
            
            
        except Exception as e:
            print(f"Recommender error: {str(e)}")
            state["recommendation"] = "Vui lÃ²ng gáº·p bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t."
            state["final_response"] = state["recommendation"]
            state["messages"].append(f"âŒ Recommender: Error - {str(e)}")
        
        return state
    
    def _format_final_response(self, state: "GraphState") -> str:
        """
        Format the final response for the user.
        
        Args:
            state: Current graph state
            
        Returns:
            Formatted final response string
        """
        diagnosis = state.get("diagnosis", {})
        risk_assessment = state.get("risk_assessment", {})
        recommendation = state.get("recommendation", "")
        
        response = f"""**ğŸ©º PhÃ¢n tÃ­ch y táº¿:**

**Cháº©n Ä‘oÃ¡n sÆ¡ bá»™:** {diagnosis.get('primary_diagnosis', 'KhÃ´ng xÃ¡c Ä‘á»‹nh')}

**Má»©c Ä‘á»™ rá»§i ro:** {risk_assessment.get('risk_level', 'MEDIUM')}

{recommendation}

---
*LÆ°u Ã½: ÄÃ¢y lÃ  phÃ¢n tÃ­ch sÆ¡ bá»™. Vui lÃ²ng tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© chuyÃªn khoa Ä‘á»ƒ cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c.*"""
        
        return response
