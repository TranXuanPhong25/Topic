"""
ConversationAgent Node: Handles normal conversations using clinic information and FAQs.
"""
import logging
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from ..medical_diagnostic_graph import GraphState

logger = logging.getLogger(__name__)


class ConversationAgentNode:
    """
    ConversationAgent Node: Handles normal conversations using tools.
    
    Tools: CareGuideTool, FAQTool, ClinicInfoTool, PriceTableTool
    """
    
    def __init__(self, gemini_model, knowledge_base):
        """
        Initialize the ConversationAgent node.
        
        Args:
            gemini_model: Configured Gemini model for text generation
            knowledge_base: FAQ knowledge base for clinic information
        """
        self.gemini_model = gemini_model
        self.knowledge_base = knowledge_base
    
    def __call__(self, state: "GraphState") -> "GraphState":
        """
        Execute the conversation agent logic.
        
        Args:
            state: Current graph state
            
        Returns:
            Updated graph state with conversation output
        """
        logger.info("üí¨ ConversationAgent: Handling conversation...")
        
        user_input = state.get("input", "")
        
        try:
            # Search knowledge base for relevant FAQ
            faq_results = self.knowledge_base.search_faqs(user_input, limit=3)
            
            # Build context from FAQ
            context = "\n\n".join([
                f"Q: {faq['question']}\nA: {faq['answer']}"
                for faq in faq_results
            ])
            
            # Use Gemini to generate response
            conversation_prompt = f"""B·∫°n l√† tr·ª£ l√Ω y t·∫ø th√¢n thi·ªán cho ph√≤ng kh√°m. Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·ªánh nh√¢n.

Th√¥ng tin ph√≤ng kh√°m:
- T√™n: {self.knowledge_base.clinic_info['name']}
- Gi·ªù l√†m vi·ªác: {self.knowledge_base.clinic_info['hours']}
- ƒêi·ªán tho·∫°i: {self.knowledge_base.clinic_info['phone']}

C√¢u h·ªèi th∆∞·ªùng g·∫∑p li√™n quan:
{context}

C√¢u h·ªèi c·ªßa b·ªánh nh√¢n: "{user_input}"

Tr·∫£ l·ªùi ng·∫Øn g·ªçn, h·ªØu √≠ch, chuy√™n nghi·ªáp (2-3 c√¢u):"""

            response = self.gemini_model.generate_content(conversation_prompt)
            conversation_output = response.text.strip()
            
            state["conversation_output"] = conversation_output
            state["final_response"] = conversation_output
            state["messages"].append("‚úÖ ConversationAgent: Response generated")
            
            logger.info(f"Conversation response: {conversation_output[:100]}...")
            
        except Exception as e:
            logger.error(f"ConversationAgent error: {str(e)}")
            state["conversation_output"] = "Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë. Vui l√≤ng g·ªçi ph√≤ng kh√°m ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."
            state["final_response"] = state["conversation_output"]
            state["messages"].append(f"‚ùå ConversationAgent: Error - {str(e)}")
        
        return state
