"""
LangGraph-based Medical Diagnostic System
Implements the complete diagnostic flow with routing, diagnosis, risk assessment, and recommendations.
"""
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, List, Dict, Any, Optional, Literal
import operator
import logging
import google.generativeai as genai
from vision.gemini_vision_analyzer import GeminiVisionAnalyzer
from knowledge_base import FAQKnowledgeBase
from handlers.appointment import AppointmentHandler
from datetime import datetime
import json
import re

logger = logging.getLogger(__name__)


# ============================================================================
# GRAPH STATE DEFINITION (As specified in requirements)
# ============================================================================

class GraphState(TypedDict):
    """
    Comprehensive state for the medical AI system graph.
    All data flows through this shared state according to the diagram.
    """
    # Input and routing
    input: str  # Initial user query
    intent: str  # normal_conversation, needs_examiner, symptoms_only, image_and_symptoms
    
    # Image and symptoms
    image: Optional[str]  # Base64 encoded image
    symptoms: str  # Extracted symptoms from input
    
    # Vision analysis
    image_analysis_result: Dict[str, Any]  # Output from ImageAnalyzer
    
    # Combined analysis
    combined_analysis: str  # Merged symptoms and image analysis
    
    # Diagnosis and risk
    diagnosis: Dict[str, Any]  # Output from DiagnosisEngine
    risk_assessment: Dict[str, Any]  # Output from RiskAssessor
    
    # Investigation and retrieval
    investigation_plan: List[Dict[str, Any]]  # Generated list of investigations
    retrieved_documents: List[Dict[str, Any]]  # Context from Vector DB and KG
    
    # Recommendations
    recommendation: str  # Final actionable advice
    
    # Conversation and appointment
    conversation_output: str  # Result from ConversationAgent
    appointment_details: Dict[str, Any]  # Result from AppointmentScheduler
    
    # Final output
    final_response: str  # Message to be sent to user
    
    # Logging and metadata
    messages: Annotated[List[str], operator.add]  # Append-only log
    metadata: Dict[str, Any]  # Additional context


# ============================================================================
# MEDICAL DIAGNOSTIC GRAPH - Main Implementation
# ============================================================================

class MedicalDiagnosticGraph:
    """
    Comprehensive medical diagnostic system using LangGraph.
    
    Flow:
    1. Router: Classifies intent and extracts symptoms/image
    2. Conditional branching:
       - normal_conversation ‚Üí ConversationAgent ‚Üí END
       - needs_examiner ‚Üí AppointmentScheduler ‚Üí END
       - image_and_symptoms ‚Üí ImageAnalyzer ‚Üí CombineAnalysis ‚Üí DiagnosisEngine
       - symptoms_only ‚Üí DiagnosisEngine
    3. DiagnosisEngine (includes internal RiskAssessor)
    4. Parallel: InvestigationGenerator + DocumentRetriever
    5. Recommender (joins both paths) ‚Üí END
    """
    
    def __init__(self, google_api_key: str):
        """
        Initialize the medical diagnostic system.
        
        Args:
            google_api_key: Google API key for Gemini
        """
        self.google_api_key = google_api_key
        
        # Initialize components
        self.vision_analyzer = GeminiVisionAnalyzer(google_api_key)
        self.knowledge_base = FAQKnowledgeBase()
        self.appointment_handler = AppointmentHandler()
        
        # Initialize Gemini for text reasoning
        genai.configure(api_key=google_api_key)
        self.gemini_model = genai.GenerativeModel(
            model_name="gemini-2.5-flash-lite",
            generation_config={
                "temperature": 0.4,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
        )
        
        # Build the graph
        self.graph = self._build_graph()
        
        logger.info("MedicalDiagnosticGraph initialized successfully")
    
    def _build_graph(self) -> StateGraph:
        """
        Build the LangGraph workflow according to the diagram.
        
        Graph structure:
        Router (entry) ‚Üí Conditional branching:
          - ConversationAgent ‚Üí END
          - AppointmentScheduler ‚Üí END
          - ImageAnalyzer ‚Üí CombineAnalysis ‚Üí DiagnosisEngine ‚Üí [InvestigationGenerator, DocumentRetriever] ‚Üí Recommender ‚Üí END
          - DiagnosisEngine ‚Üí [InvestigationGenerator, DocumentRetriever] ‚Üí Recommender ‚Üí END
        """
        workflow = StateGraph(GraphState)
        
        # Add all nodes (agents/processors)
        workflow.add_node("router", self._router_node)
        workflow.add_node("conversation_agent", self._conversation_agent_node)
        workflow.add_node("appointment_scheduler", self._appointment_scheduler_node)
        workflow.add_node("image_analyzer", self._image_analyzer_node)
        workflow.add_node("combine_analysis", self._combine_analysis_node)
        workflow.add_node("diagnosis_engine", self._diagnosis_engine_node)
        workflow.add_node("investigation_generator", self._investigation_generator_node)
        workflow.add_node("document_retriever", self._document_retriever_node)
        workflow.add_node("recommender", self._recommender_node)
        
        # Set entry point
        workflow.set_entry_point("router")
        
        # Conditional edges from Router
        workflow.add_conditional_edges(
            "router",
            self._route_based_on_intent,
            {
                "normal_conversation": "conversation_agent",
                "needs_examiner": "appointment_scheduler",
                "image_and_symptoms": "image_analyzer",
                "symptoms_only": "diagnosis_engine",
            }
        )
        
        # Linear edges for image analysis path
        workflow.add_edge("image_analyzer", "combine_analysis")
        workflow.add_edge("combine_analysis", "diagnosis_engine")
        
        # Sequential edges from DiagnosisEngine (to avoid concurrent state updates)
        # First generate investigations, then retrieve documents, then recommend
        workflow.add_edge("diagnosis_engine", "investigation_generator")
        workflow.add_edge("investigation_generator", "document_retriever")
        workflow.add_edge("document_retriever", "recommender")
        
        # End points
        workflow.add_edge("conversation_agent", END)
        workflow.add_edge("appointment_scheduler", END)
        workflow.add_edge("recommender", END)
        
        # Compile the graph
        return workflow.compile()
    
    # ========================================================================
    # ROUTING FUNCTION
    # ========================================================================
    
    def _route_based_on_intent(self, state: GraphState) -> Literal["normal_conversation", "needs_examiner", "image_and_symptoms", "symptoms_only"]:
        """
        Route to appropriate node based on classified intent.
        """
        intent = state.get("intent", "normal_conversation")
        logger.info(f"Routing to: {intent}")
        return intent
    
    # ========================================================================
    # NODE IMPLEMENTATIONS
    # ========================================================================
    
    def _router_node(self, state: GraphState) -> GraphState:
        """
        Router Node: Classifies intent and extracts symptoms/image.
        
        Logic:
        1. Analyze user input
        2. Determine intent (conversation, examiner, symptoms, image+symptoms)
        3. Extract symptoms if present
        4. Extract image if present
        """
        # Check if router has already run (avoid duplicate executions)
        if state.get("intent") and state.get("intent") != "":
            logger.info("üîÄ Router: Already classified, skipping...")
            return state
        
        logger.info("üîÄ Router: Classifying user intent...")
        
        user_input = state.get("input", "")
        image = state.get("image")
        
        # Initialize state fields
        state["symptoms"] = ""
        state["intent"] = "normal_conversation"
        state["metadata"] = state.get("metadata", {})
        state["messages"] = state.get("messages", [])
        
        try:
            # Use Gemini to classify intent and extract symptoms
            classification_prompt = f"""Ph√¢n t√≠ch ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ JSON v·ªõi c√°c tr∆∞·ªùng sau:

                                        Input: "{user_input}"
                                        C√≥ h√¨nh ·∫£nh: {"C√≥" if image else "Kh√¥ng"}

                                        X√°c ƒë·ªãnh:
                                        1. intent: "normal_conversation" (h·ªèi th√¥ng tin ph√≤ng kh√°m, gi√° c·∫£, FAQ), 
                                                "needs_examiner" (mu·ªën ƒë·∫∑t l·ªãch kh√°m ho·∫∑c c·∫ßn g·∫∑p b√°c sƒ©), 
                                                "symptoms_only" (m√¥ t·∫£ tri·ªáu ch·ª©ng kh√¥ng c√≥ h√¨nh ·∫£nh), 
                                                "image_and_symptoms" (c√≥ h√¨nh ·∫£nh y khoa v√† tri·ªáu ch·ª©ng)
                                        2. symptoms: chu·ªói tri·ªáu ch·ª©ng ƒë∆∞·ª£c tr√≠ch xu·∫•t (n·∫øu c√≥), r·ªóng n·∫øu kh√¥ng

                                        Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng c√≥ vƒÉn b·∫£n b·ªï sung:
                                        {{"intent": "...", "symptoms": "..."}}"""

            response = self.gemini_model.generate_content(classification_prompt)
            result_text = response.text.strip()
            
            # Parse JSON response
            # Remove markdown code blocks if present
            result_text = re.sub(r'```json\s*|\s*```', '', result_text)
            result = json.loads(result_text)
            
            intent = result.get("intent", "normal_conversation")
            symptoms = result.get("symptoms", "")
            
            # Override intent if image is present and symptoms detected
            if image and symptoms:
                intent = "image_and_symptoms"
            elif not image and symptoms:
                intent = "symptoms_only"
            
            state["intent"] = intent
            state["symptoms"] = symptoms
            state["messages"].append(f"‚úÖ Router: Intent classified as '{intent}'")
            
            if symptoms:
                state["messages"].append(f"‚úÖ Router: Extracted symptoms: {symptoms[:100]}...")
            
            logger.info(f"Intent: {intent}, Symptoms: {symptoms[:50]}...")
            
        except Exception as e:
            logger.error(f"Router error: {str(e)}")
            state["intent"] = "normal_conversation"
            state["messages"].append(f"‚ùå Router: Error - {str(e)}, defaulting to conversation")
        
        return state
    
    def _conversation_agent_node(self, state: GraphState) -> GraphState:
        """
        ConversationAgent Node: Handles normal conversations using tools.
        
        Tools: CareGuideTool, FAQTool, ClinicInfoTool, PriceTableTool
        """
        logger.info("üí¨ ConversationAgent: Handling conversation...")
        
        user_input = state.get("input", "")
        
        try:
            # Search knowledge base for relevant FAQ
            faq_results = self.knowledge_base.search_faqs(user_input, limit=3)
            
            # Build context from FAQ
            context = "\n\n".join([
                f"Q: {faq['question']}\nA: {faq['answer']}"
                for faq in faq_results
            ])
            
            # Use Gemini to generate response
            conversation_prompt = f"""B·∫°n l√† tr·ª£ l√Ω y t·∫ø th√¢n thi·ªán cho ph√≤ng kh√°m. Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·ªánh nh√¢n.

                                        Th√¥ng tin ph√≤ng kh√°m:
                                        - T√™n: {self.knowledge_base.clinic_info['name']}
                                        - Gi·ªù l√†m vi·ªác: {self.knowledge_base.clinic_info['hours']}
                                        - ƒêi·ªán tho·∫°i: {self.knowledge_base.clinic_info['phone']}

                                        C√¢u h·ªèi th∆∞·ªùng g·∫∑p li√™n quan:
                                        {context}

                                        C√¢u h·ªèi c·ªßa b·ªánh nh√¢n: "{user_input}"

                                        Tr·∫£ l·ªùi ng·∫Øn g·ªçn, h·ªØu √≠ch, chuy√™n nghi·ªáp (2-3 c√¢u):"""

            response = self.gemini_model.generate_content(conversation_prompt)
            conversation_output = response.text.strip()
            
            state["conversation_output"] = conversation_output
            state["final_response"] = conversation_output
            state["messages"].append("‚úÖ ConversationAgent: Response generated")
            
            logger.info(f"Conversation response: {conversation_output[:100]}...")
            
        except Exception as e:
            logger.error(f"ConversationAgent error: {str(e)}")
            state["conversation_output"] = "Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë. Vui l√≤ng g·ªçi ph√≤ng kh√°m ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."
            state["final_response"] = state["conversation_output"]
            state["messages"].append(f"‚ùå ConversationAgent: Error - {str(e)}")
        
        return state
    
    def _appointment_scheduler_node(self, state: GraphState) -> GraphState:
        """
        AppointmentScheduler Node: Handles appointment booking.
        """
        logger.info("üìÖ AppointmentScheduler: Handling booking...")
        
        user_input = state.get("input", "")
        # TODO: notworking
        try:
            # Extract appointment details using Gemini
            extraction_prompt = f"""Tr√≠ch xu·∫•t th√¥ng tin ƒë·∫∑t l·ªãch t·ª´ ƒë·∫ßu v√†o. Tr·∫£ v·ªÅ JSON:

            Input: "{user_input}"

            Tr√≠ch xu·∫•t (n·∫øu c√≥):
            - patient_name: t√™n b·ªánh nh√¢n
            - date: ng√†y (YYYY-MM-DD)
            - time: gi·ªù (HH:MM)
            - reason: l√Ω do kh√°m

            N·∫øu thi·∫øu th√¥ng tin, ƒë·∫∑t null. Ch·ªâ tr·∫£ v·ªÅ JSON:
            {{"patient_name": "...", "date": "...", "time": "...", "reason": "..."}}"""

            response = self.gemini_model.generate_content(extraction_prompt)
            result_text = response.text.strip()
            result_text = re.sub(r'```json\s*|\s*```', '', result_text)
            appointment_data = json.loads(result_text)
            
            # Check if we have enough information
            missing_fields = []
            for field in ["patient_name", "date", "time", "reason"]:
                if not appointment_data.get(field):
                    missing_fields.append(field)
            
            if missing_fields:
                # Generate prompt for missing information
                missing_str = ", ".join(missing_fields)
                response_text = f"ƒê·ªÉ ƒë·∫∑t l·ªãch, t√¥i c·∫ßn th√™m th√¥ng tin: {missing_str}. B·∫°n c√≥ th·ªÉ cung c·∫•p kh√¥ng?"
            else:
                # Validate and create appointment (simplified - in real app, use AppointmentHandler)
                response_text = f"""ƒê√£ ƒë·∫∑t l·ªãch th√†nh c√¥ng!

üìÖ Th√¥ng tin:
- B·ªánh nh√¢n: {appointment_data['patient_name']}
- Ng√†y: {appointment_data['date']}
- Gi·ªù: {appointment_data['time']}
- L√Ω do: {appointment_data['reason']}

Ch√∫ng t√¥i s·∫Ω g·ª≠i x√°c nh·∫≠n qua tin nh·∫Øn. C·∫£m ∆°n!"""
            
            state["appointment_details"] = appointment_data
            state["final_response"] = response_text
            state["messages"].append("‚úÖ AppointmentScheduler: Processed")
            
            logger.info(f"Appointment: {appointment_data}")
            
        except Exception as e:
            logger.error(f"AppointmentScheduler error: {str(e)}")
            state["appointment_details"] = {}
            state["final_response"] = "ƒê·ªÉ ƒë·∫∑t l·ªãch, vui l√≤ng cung c·∫•p: t√™n, ng√†y, gi·ªù, v√† l√Ω do kh√°m."
            state["messages"].append(f"‚ùå AppointmentScheduler: Error - {str(e)}")
        
        return state
    
    def _image_analyzer_node(self, state: GraphState) -> GraphState:
        """
        ImageAnalyzer Node: Analyzes image in context of symptoms.
        """
        logger.info("üîç ImageAnalyzer: Analyzing medical image...")
        
        image = state.get("image")
        symptoms = state.get("symptoms", "")
        
        try:
            if not image:
                raise ValueError("No image provided")
            
            # Analyze image using GeminiVisionAnalyzer
            analysis_result = self.vision_analyzer.analyze_image(image, symptoms)
            
            state["image_analysis_result"] = analysis_result
            state["messages"].append("‚úÖ ImageAnalyzer: Image analyzed successfully")
            
            logger.info(f"Image analysis confidence: {analysis_result.get('confidence', 0)}")
            
        except Exception as e:
            logger.error(f"ImageAnalyzer error: {str(e)}")
            state["image_analysis_result"] = {
                "visual_description": "",
                "visual_qa_results": {},
                "confidence": 0.0,
                "error": str(e)
            }
            state["messages"].append(f"‚ùå ImageAnalyzer: Error - {str(e)}")
        
        return state
    
    def _combine_analysis_node(self, state: GraphState) -> GraphState:
        """
        CombineAnalysis Node: Merges text symptoms and image analysis.
        """
        logger.info("üîó CombineAnalysis: Merging symptoms and image analysis...")
        
        symptoms = state.get("symptoms", "")
        image_analysis = state.get("image_analysis_result", {})
        
        try:
            # Combine information
            visual_desc = image_analysis.get("visual_description", "")
            visual_qa = image_analysis.get("visual_qa_results", {})
            
            combined = f"""**Tri·ªáu ch·ª©ng c·ªßa b·ªánh nh√¢n:**
{symptoms}

**Ph√¢n t√≠ch h√¨nh ·∫£nh:**
M√¥ t·∫£: {visual_desc}

**K·∫øt qu·∫£ Visual Q&A:**
{json.dumps(visual_qa, ensure_ascii=False, indent=2)}"""
            
            state["combined_analysis"] = combined
            state["messages"].append("‚úÖ CombineAnalysis: Merged successfully")
            
            logger.info(f"Combined analysis length: {len(combined)} characters")
            
        except Exception as e:
            logger.error(f"CombineAnalysis error: {str(e)}")
            state["combined_analysis"] = symptoms  # Fallback to symptoms only
            state["messages"].append(f"‚ùå CombineAnalysis: Error - {str(e)}")
        
        return state
    
    def _diagnosis_engine_node(self, state: GraphState) -> GraphState:
        """
        DiagnosisEngine Node: Runs core diagnostic logic with risk assessment.
        
        Input: combined_analysis (if image) or symptoms (if symptoms only)
        Internally calls RiskAssessor to refine diagnosis
        """
        logger.info("ü©∫ DiagnosisEngine: Running diagnostic analysis...")
        
        # Get input - use combined_analysis if available, otherwise symptoms
        analysis_input = state.get("combined_analysis") or state.get("symptoms", "")
        
        try:
            # Generate diagnosis using Gemini
            diagnosis_prompt = f"""B·∫°n l√† b√°c sƒ© AI chuy√™n nghi·ªáp. Ph√¢n t√≠ch th√¥ng tin b·ªánh nh√¢n v√† ƒë∆∞a ra ch·∫©n ƒëo√°n s∆° b·ªô.

**Th√¥ng tin b·ªánh nh√¢n:**
{analysis_input}

**Nhi·ªám v·ª•:**
1. ƒê∆∞a ra c√°c ch·∫©n ƒëo√°n kh·∫£ nƒÉng cao (top 2-3)
2. M·ª©c ƒë·ªô nghi√™m tr·ªçng
3. C√°c tri·ªáu ch·ª©ng ƒë√°ng lo ng·∫°i

Tr·∫£ v·ªÅ JSON:
{{
    "primary_diagnosis": "Ch·∫©n ƒëo√°n ch√≠nh",
    "differential_diagnoses": ["Ch·∫©n ƒëo√°n kh√°c 1", "Ch·∫©n ƒëo√°n kh√°c 2"],
    "severity": "mild/moderate/severe/critical",
    "concerning_symptoms": ["Tri·ªáu ch·ª©ng 1", "Tri·ªáu ch·ª©ng 2"],
    "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn"
}}

Ch·ªâ tr·∫£ v·ªÅ JSON:"""

            response = self.gemini_model.generate_content(diagnosis_prompt)
            result_text = response.text.strip()
            result_text = re.sub(r'```json\s*|\s*```', '', result_text)
            diagnosis = json.loads(result_text)
            
            # Internal risk assessment
            severity = diagnosis.get("severity", "moderate")
            risk_level = self._assess_risk_internal(severity, diagnosis)
            
            state["diagnosis"] = diagnosis
            state["risk_assessment"] = risk_level
            state["messages"].append(f"‚úÖ DiagnosisEngine: Diagnosis complete (severity: {severity})")
            
            logger.info(f"Diagnosis: {diagnosis.get('primary_diagnosis', 'Unknown')}")
            
        except Exception as e:
            logger.error(f"DiagnosisEngine error: {str(e)}")
            state["diagnosis"] = {
                "primary_diagnosis": "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh",
                "differential_diagnoses": [],
                "severity": "moderate",
                "concerning_symptoms": [],
                "explanation": f"L·ªói: {str(e)}"
            }
            state["risk_assessment"] = {"risk_level": "MEDIUM", "explanation": "M·∫∑c ƒë·ªãnh do l·ªói"}
            state["messages"].append(f"‚ùå DiagnosisEngine: Error - {str(e)}")
        
        return state
    
    def _assess_risk_internal(self, severity: str, diagnosis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Internal risk assessor (called by DiagnosisEngine).
        """
        risk_mapping = {
            "mild": "LOW",
            "moderate": "MEDIUM",
            "severe": "HIGH",
            "critical": "CRITICAL"
        }
        
        risk_level = risk_mapping.get(severity.lower(), "MEDIUM")
        
        # Check for concerning symptoms
        concerning = diagnosis.get("concerning_symptoms", [])
        if len(concerning) >= 3 and risk_level == "MEDIUM":
            risk_level = "HIGH"
        
        return {
            "risk_level": risk_level,
            "explanation": f"D·ª±a tr√™n m·ª©c ƒë·ªô nghi√™m tr·ªçng: {severity}",
            "requires_immediate_attention": risk_level in ["HIGH", "CRITICAL"]
        }
    
    def _investigation_generator_node(self, state: GraphState) -> GraphState:
        """
        InvestigationGenerator Node: Generates potential follow-up tests.
        """
        logger.info("üî¨ InvestigationGenerator: Generating investigation plan...")
        
        diagnosis = state.get("diagnosis", {})
        
        try:
            # Generate investigation plan using Gemini
            investigation_prompt = f"""D·ª±a tr√™n ch·∫©n ƒëo√°n, ƒë·ªÅ xu·∫•t c√°c x√©t nghi·ªám/ki·ªÉm tra c·∫ßn thi·∫øt.

**Ch·∫©n ƒëo√°n:**
{json.dumps(diagnosis, ensure_ascii=False, indent=2)}

**Nhi·ªám v·ª•:** ƒê·ªÅ xu·∫•t 3-5 x√©t nghi·ªám/ki·ªÉm tra ph√π h·ª£p.

Tr·∫£ v·ªÅ JSON array:
[
    {{"test_name": "T√™n x√©t nghi·ªám", "reason": "L√Ω do", "priority": "high/medium/low"}},
    ...
]

Ch·ªâ tr·∫£ v·ªÅ JSON:"""

            response = self.gemini_model.generate_content(investigation_prompt)
            result_text = response.text.strip()
            result_text = re.sub(r'```json\s*|\s*```', '', result_text)
            investigations = json.loads(result_text)
            
            state["investigation_plan"] = investigations
            state["messages"].append(f"‚úÖ InvestigationGenerator: {len(investigations)} tests suggested")
            
            logger.info(f"Generated {len(investigations)} investigation items")
            
        except Exception as e:
            logger.error(f"InvestigationGenerator error: {str(e)}")
            state["investigation_plan"] = []
            state["messages"].append(f"‚ùå InvestigationGenerator: Error - {str(e)}")
        
        return state
    
    def _document_retriever_node(self, state: GraphState) -> GraphState:
        """
        DocumentRetriever Node: Performs information augmentation.
        
        Queries Vector Database (embeddings) and Knowledge Graph (KB).
        """
        logger.info("üìö DocumentRetriever: Retrieving relevant medical documents...")
        
        diagnosis = state.get("diagnosis", {})
        primary_diagnosis = diagnosis.get("primary_diagnosis", "")
        
        try:
            # Search knowledge base for relevant information
            # In real implementation, this would query vector DB + KG
            search_results = self.knowledge_base.search_faqs(primary_diagnosis, limit=5)
            
            # Format as documents
            documents = [
                {
                    "source": "FAQ Database",
                    "content": result.get("answer", ""),
                    "relevance": 0.9
                }
                for result in search_results
            ]
            
            # Add medical knowledge (simulated)
            documents.append({
                "source": "Medical Knowledge Graph",
                "content": f"Th√¥ng tin y khoa v·ªÅ: {primary_diagnosis}",
                "relevance": 0.8
            })
            
            state["retrieved_documents"] = documents
            state["messages"].append(f"‚úÖ DocumentRetriever: Retrieved {len(documents)} documents")
            
            logger.info(f"Retrieved {len(documents)} relevant documents")
            
        except Exception as e:
            logger.error(f"DocumentRetriever error: {str(e)}")
            state["retrieved_documents"] = []
            state["messages"].append(f"‚ùå DocumentRetriever: Error - {str(e)}")
        
        return state
    
    def _recommender_node(self, state: GraphState) -> GraphState:
        """
        Recommender Node: Synthesizes investigations and retrieved context.
        
        Waits for both InvestigationGenerator and DocumentRetriever to complete.
        """
        logger.info("üí° Recommender: Generating final recommendations...")
        
        diagnosis = state.get("diagnosis", {})
        risk_assessment = state.get("risk_assessment", {})
        investigation_plan = state.get("investigation_plan", [])
        retrieved_documents = state.get("retrieved_documents", [])
        
        try:
            # Build context
            context = f"""**Ch·∫©n ƒëo√°n:**
{json.dumps(diagnosis, ensure_ascii=False, indent=2)}

**ƒê√°nh gi√° r·ªßi ro:**
{json.dumps(risk_assessment, ensure_ascii=False, indent=2)}

**K·∫ø ho·∫°ch x√©t nghi·ªám:**
{json.dumps(investigation_plan, ensure_ascii=False, indent=2)}

**T√†i li·ªáu tham kh·∫£o:**
{len(retrieved_documents)} documents retrieved"""
            
            # Generate recommendations using Gemini
            recommendation_prompt = f"""D·ª±a tr√™n ph√¢n t√≠ch, ƒë∆∞a ra khuy·∫øn ngh·ªã cu·ªëi c√πng cho b·ªánh nh√¢n.

{context}

**Nhi·ªám v·ª•:** Vi·∫øt khuy·∫øn ngh·ªã h√†nh ƒë·ªông r√µ r√†ng, d·ªÖ hi·ªÉu (3-5 c√¢u).

Bao g·ªìm:
1. H√†nh ƒë·ªông ngay l·∫≠p t·ª©c (n·∫øu c·∫ßn)
2. Khi n√†o c·∫ßn g·∫∑p b√°c sƒ©
3. X√©t nghi·ªám c·∫ßn l√†m
4. ChƒÉm s√≥c t·∫°i nh√† (n·∫øu ph√π h·ª£p)

**Khuy·∫øn ngh·ªã (ti·∫øng Vi·ªát, th√¢n thi·ªán):**"""

            response = self.gemini_model.generate_content(recommendation_prompt)
            recommendation = response.text.strip()
            
            state["recommendation"] = recommendation
            state["final_response"] = self._format_final_response(state)
            state["messages"].append("‚úÖ Recommender: Final recommendations generated")
            
            logger.info(f"Recommendation length: {len(recommendation)} characters")
            
        except Exception as e:
            logger.error(f"Recommender error: {str(e)}")
            state["recommendation"] = "Vui l√≤ng g·∫∑p b√°c sƒ© ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt."
            state["final_response"] = state["recommendation"]
            state["messages"].append(f"‚ùå Recommender: Error - {str(e)}")
        
        return state
    
    def _format_final_response(self, state: GraphState) -> str:
        """
        Format the final response for the user.
        """
        diagnosis = state.get("diagnosis", {})
        risk_assessment = state.get("risk_assessment", {})
        recommendation = state.get("recommendation", "")
        
        response = f"""**ü©∫ Ph√¢n t√≠ch y t·∫ø:**

**Ch·∫©n ƒëo√°n s∆° b·ªô:** {diagnosis.get('primary_diagnosis', 'Kh√¥ng x√°c ƒë·ªãnh')}

**M·ª©c ƒë·ªô r·ªßi ro:** {risk_assessment.get('risk_level', 'MEDIUM')}

**üí° Khuy·∫øn ngh·ªã:**
{recommendation}

---
*L∆∞u √Ω: ƒê√¢y l√† ph√¢n t√≠ch s∆° b·ªô. Vui l√≤ng tham kh·∫£o √Ω ki·∫øn b√°c sƒ© chuy√™n khoa ƒë·ªÉ ch·∫©n ƒëo√°n ch√≠nh x√°c.*"""
        
        return response
    
    # ========================================================================
    # PUBLIC API
    # ========================================================================
    
    def analyze(
        self,
        user_input: str,
        image: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Analyze user input and return diagnostic results.
        
        Args:
            user_input: User's text input
            image: Optional base64 encoded image
            metadata: Optional additional context
        
        Returns:
            Dictionary containing final_response and full state
        """
        logger.info(f"Starting analysis for input: {user_input[:100]}...")
        
        # Initialize state
        initial_state: GraphState = {
            "input": user_input,
            "image": image,
            "intent": "",
            "symptoms": "",
            "image_analysis_result": {},
            "combined_analysis": "",
            "diagnosis": {},
            "risk_assessment": {},
            "investigation_plan": [],
            "retrieved_documents": [],
            "recommendation": "",
            "conversation_output": "",
            "appointment_details": {},
            "final_response": "",
            "messages": [],
            "metadata": metadata or {}
        }
        
        try:
            # Execute the graph (returns final state only, not streaming)
            final_state = self.graph.invoke(initial_state)
            
            # Extract only the unique execution steps (final state messages)
            # LangGraph invoke() returns final state, but messages list accumulates all intermediate states
            # Filter to keep only one message per node
            seen_nodes = set()
            cleaned_messages = []
            
            for msg in final_state.get("messages", []):
                # Extract node name from message (e.g., "‚úÖ Router:" -> "Router")
                if ":" in msg:
                    node_part = msg.split(":")[0].replace("‚úÖ", "").replace("‚ùå", "").strip()
                    # Create a unique key for this message
                    msg_key = f"{node_part}:{msg.split(':')[1][:50] if ':' in msg else ''}"
                    
                    if msg_key not in seen_nodes:
                        cleaned_messages.append(msg)
                        seen_nodes.add(msg_key)
            
            return {
                "success": True,
                "final_response": final_state["final_response"],
                "intent": final_state.get("intent"),
                "diagnosis": final_state.get("diagnosis"),
                "risk_assessment": final_state.get("risk_assessment"),
                "investigation_plan": final_state.get("investigation_plan"),
                "messages": cleaned_messages,  # Use cleaned messages
                "metadata": final_state.get("metadata", {})
            }
            
        except Exception as e:
            logger.error(f"Graph execution error: {str(e)}")
            return {
                "success": False,
                "final_response": "Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c li√™n h·ªá ph√≤ng kh√°m.",
                "error": str(e),
                "messages": [f"‚ùå Graph execution error: {str(e)}"]
            }


# ============================================================================
# EXAMPLE USAGE
# ============================================================================

if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    # Initialize the graph
    graph = MedicalDiagnosticGraph(
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    
    # Example 1: Normal conversation
    print("\n" + "="*80)
    print("Example 1: Normal Conversation")
    print("="*80)
    result1 = graph.analyze("Ph√≤ng kh√°m m·ªü c·ª≠a l√∫c m·∫•y gi·ªù?")
    print(f"Intent: {result1['intent']}")
    print(f"Response: {result1['final_response']}")
    
    # Example 2: Appointment booking
    print("\n" + "="*80)
    print("Example 2: Appointment Booking")
    print("="*80)
    result2 = graph.analyze("T√¥i mu·ªën ƒë·∫∑t l·ªãch kh√°m v√†o ng√†y mai l√∫c 2 gi·ªù chi·ªÅu")
    print(f"Intent: {result2['intent']}")
    print(f"Response: {result2['final_response']}")
    
    # Example 3: Symptoms only
    print("\n" + "="*80)
    print("Example 3: Symptoms Analysis")
    print("="*80)
    result3 = graph.analyze("T√¥i b·ªã ƒëau ƒë·∫ßu v√† s·ªët t·ª´ 2 ng√†y nay, nhi·ªát ƒë·ªô kho·∫£ng 38.5¬∞C")
    print(f"Intent: {result3['intent']}")
    print(f"Response: {result3['final_response']}")
    
    print("\n" + "="*80)
    print("Graph execution complete!")
    print("="*80)
