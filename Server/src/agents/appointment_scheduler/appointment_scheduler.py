from datetime import datetime
from langchain.agents import create_agent
from langchain_core.language_models import BaseChatModel

from .prompts import APPOINTMENT_SCHEDULER_SYSTEM_PROMPT
from .tools import check_appointment_availability, book_appointment, get_available_time_slots, get_current_datetime
from ..medical_diagnostic_graph import GraphState
from ..utils.message_builder import build_messages_with_history, extract_text_from_gemini_message
from src.configs.agent_config import HumanMessage, AIMessage

class AppointmentSchedulerNode:
    """
    React Agent-based Appointment Scheduler.
    Uses LangGraph's create_react_agent to intelligently handle appointment booking
    by deciding which tools to use based on user input.
    """
    
    def __init__(self, model: BaseChatModel):
        # Create React agent with tools
        # The agent will automatically call tools and continue until it provides a final response
        self.agent = create_agent(
            model=model,
            system_prompt=APPOINTMENT_SCHEDULER_SYSTEM_PROMPT,
            tools=[
                get_current_datetime,
                check_appointment_availability,
                book_appointment,
                get_available_time_slots
            ]
        )
    
    def _get_current_goal(self, state: "GraphState") -> str:
        """
        Extract the goal for the current step from the plan
        
        Args:
            state: Current graph state
            
        Returns:
            Goal string or empty string if not found
        """
        plan = state.get("plan", [])
        current_step_index = state.get("current_step", 0)
        
        if not plan or current_step_index >= len(plan):
            return ""
        
        current_plan_step = plan[current_step_index]
        goal = current_plan_step.get("goal", "")
        
        if goal:
            print(f"ğŸ¯ Current Goal: {goal}")
        
        return goal
    
    def _get_current_context(self, state: "GraphState") -> dict:
        """
        Extract context and user_context for the current step from the plan
        
        Args:
            state: Current graph state
            
        Returns:
            Dict with 'context' and 'user_context' keys (empty strings if not found)
        """
        plan = state.get("plan", [])
        current_step_index = state.get("current_step", 0)
        
        if not plan or current_step_index >= len(plan):
            return {"context": "", "user_context": ""}
        
        current_plan_step = plan[current_step_index]
        context = current_plan_step.get("context", "")
        user_context = current_plan_step.get("user_context", "")
        
        if context:
            print(f"ğŸ“ Context: {context[:100]}...")
        if user_context:
            print(f"ğŸ‘¤ User Context: {user_context[:100]}...")
        
        return {"context": context, "user_context": user_context}

    async def __call__(self, state: "GraphState") -> "GraphState":
        
        user_input = state.get("input", "")
        
        try:
            # Inject current datetime directly into user prompt
            now = datetime.now()
            datetime_context = f"\n[CONTEXT: Current datetime is {now.strftime('%A, %B %d, %Y')} at {now.strftime('%H:%M')} ({now.strftime('%Y-%m-%d %H:%M:%S')})]"
            enriched_user_input = user_input + datetime_context

            messages = build_messages_with_history("", enriched_user_input, state.get("chat_history", []))
            

            result = await self.agent.ainvoke({"messages": messages})
            agent_messages = result.get("messages", [])
            
            print(f"ğŸ“… AppointmentScheduler: Processing {len(agent_messages)} messages")
            print("=" * 80)
            
            # Trace all messages for debugging
            from langchain_core.messages import AIMessage as LangChainAIMessage, ToolMessage
            
            for i, msg in enumerate(agent_messages):
                msg_type = type(msg).__name__
                print(f"\n[Message {i+1}/{len(agent_messages)}] Type: {msg_type}")
                
                if isinstance(msg, ToolMessage):
                    print(f"  ğŸ”§ Tool: {msg.name}")
                    print(f"  ğŸ“¤ Output: {msg.content[:200]}..." if len(msg.content) > 200 else f"  ğŸ“¤ Output: {msg.content}")
                    
                elif isinstance(msg, LangChainAIMessage):
                    if hasattr(msg, 'tool_calls') and msg.tool_calls:
                        print(f"  ğŸ¤– AI calling tools: {[tc['name'] for tc in msg.tool_calls]}")
                        for tc in msg.tool_calls:
                            print(f"     - {tc['name']}({tc.get('args', {})})")
                    
                    if hasattr(msg, 'content') and msg.content:
                        content_preview = msg.content[:150] if len(msg.content) > 150 else msg.content
                        print(f"  ğŸ’¬ AI Response: {content_preview}...")
                    else:
                        print(f"  ğŸ’¬ AI Response: {msg}")
                else:
                    print(f"  ğŸ“ Content: {str(msg)[:150]}...")
            
            print("=" * 80)
            
            # Find the last AI message (not Tool message) with actual content
            final_response = ""
            last_tool_output = None
            
            for msg in reversed(agent_messages):
                # Capture the last tool output for fallback response generation
                if isinstance(msg, ToolMessage) and last_tool_output is None:
                    last_tool_output = msg.content
                    continue
                    
                # Look for AI messages with content
                if isinstance(msg, LangChainAIMessage):
                    if hasattr(msg, 'content') and msg.content and msg.content.strip():
                        # Make sure it's not a tool call response (which might be JSON)
                        content = msg.content.strip()
                        # Check if content looks like JSON tool output
                        if not (content.startswith('{') and content.endswith('}')):
                            final_response = content
                            break
            
            # If no valid final response found, generate one based on tool output
            if not final_response:
                print("âš ï¸  No valid final response found from agent")
                
                if last_tool_output:
                    print(f"  â„¹ï¸  Using last tool output to generate response: {last_tool_output[:100]}...")
                    # Parse tool output and generate appropriate response
                    try:
                        import json
                        tool_result = json.loads(last_tool_output)
                        
                        # Handle check_appointment_availability response
                        if "available" in tool_result:
                            if tool_result.get("available"):
                                date = tool_result.get("date", "")
                                time = tool_result.get("time", "")
                                final_response = f"âœ… Tin tá»‘t! Lá»‹ch háº¹n vÃ o ngÃ y {date} lÃºc {time} váº«n cÃ²n trá»‘ng. Äá»ƒ hoÃ n táº¥t Ä‘áº·t lá»‹ch, tÃ´i cáº§n xÃ¡c nháº­n thÃªm: tÃªn Ä‘áº§y Ä‘á»§ cá»§a báº¡n, lÃ½ do khÃ¡m, vÃ  sá»‘ Ä‘iá»‡n thoáº¡i liÃªn há»‡."
                            else:
                                error = tool_result.get("error", "")
                                alternatives = tool_result.get("alternatives", [])
                                if alternatives:
                                    final_response = f"âŒ Xin lá»—i, {error}. Báº¡n cÃ³ thá»ƒ chá»n cÃ¡c khung giá» trá»‘ng khÃ¡c: {', '.join(alternatives[:3])}."
                                else:
                                    final_response = f"âŒ Xin lá»—i, {error}. Vui lÃ²ng chá»n ngÃ y hoáº·c giá» khÃ¡c."
                        
                        # Handle book_appointment response
                        elif "success" in tool_result:
                            if tool_result.get("success"):
                                confirmation = tool_result.get("confirmation", {})
                                final_response = f"ğŸ‰ ÄÃ£ Ä‘áº·t lá»‹ch thÃ nh cÃ´ng!\n\nğŸ“‹ **Chi tiáº¿t cuá»™c háº¹n:**\n- TÃªn: {confirmation.get('patient_name', 'N/A')}\n- NgÃ y: {confirmation.get('date', 'N/A')}\n- Giá»: {confirmation.get('time', 'N/A')}\n- LÃ½ do: {confirmation.get('reason', 'N/A')}\n\nChÃºng tÃ´i sáº½ liÃªn há»‡ nháº¯c nhá»Ÿ trÆ°á»›c ngÃ y khÃ¡m. Cáº£m Æ¡n báº¡n!"
                            else:
                                error = tool_result.get("error", "KhÃ´ng thá»ƒ Ä‘áº·t lá»‹ch")
                                final_response = f"âŒ {error}. Vui lÃ²ng thá»­ láº¡i hoáº·c liÃªn há»‡ phÃ²ng khÃ¡m trá»±c tiáº¿p."
                        
                        # Handle get_available_time_slots response
                        elif "available_slots" in tool_result:
                            slots = tool_result.get("available_slots", [])
                            date = tool_result.get("date", "")
                            if slots:
                                final_response = f"ğŸ“… CÃ¡c khung giá» trá»‘ng ngÃ y {date}: {', '.join(slots[:5])}. Báº¡n muá»‘n Ä‘áº·t giá» nÃ o?"
                            else:
                                final_response = f"ğŸ˜” KhÃ´ng cÃ³ khung giá» trá»‘ng ngÃ y {date}. Vui lÃ²ng chá»n ngÃ y khÃ¡c."
                        
                        else:
                            final_response = "TÃ´i Ä‘Ã£ kiá»ƒm tra thÃ´ng tin. Vui lÃ²ng cho tÃ´i biáº¿t thÃªm chi tiáº¿t Ä‘á»ƒ tiáº¿p tá»¥c Ä‘áº·t lá»‹ch."
                            
                    except json.JSONDecodeError:
                        final_response = "TÃ´i Ä‘Ã£ xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng cho tÃ´i biáº¿t náº¿u cáº§n há»— trá»£ thÃªm."
                else:
                    print("  â„¹ï¸  No tool output available")
                    final_response = "TÃ´i sáºµn sÃ ng giÃºp báº¡n Ä‘áº·t lá»‹ch khÃ¡m. Vui lÃ²ng cho tÃ´i biáº¿t: ngÃ y giá» báº¡n muá»‘n, tÃªn Ä‘áº§y Ä‘á»§, vÃ  lÃ½ do khÃ¡m?"
            else:
                print(f"âœ… Valid final response found: {final_response[:100]}...")
                
                # CRITICAL: Detect hallucination - LLM claims booking success without calling book_appointment
                booking_claimed = any(phrase in final_response.lower() for phrase in [
                    "Ä‘Ã£ Ä‘áº·t", "Ä‘Ã£ cáº­p nháº­t", "Ä‘Ã£ há»§y", "Ä‘Ã£ thay Ä‘á»•i", "Ä‘Ã£ book", 
                    "thÃ nh cÃ´ng", "Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t", "Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº·t", "Ä‘Ã£ xÃ¡c nháº­n",
                    "appointment confirmed", "successfully booked", "has been updated"
                ])
                
                # Check if book_appointment tool was actually called
                book_tool_called = any(
                    isinstance(msg, ToolMessage) and msg.name == "book_appointment"
                    for msg in agent_messages
                )
                
                if booking_claimed and not book_tool_called:
                    print("âš ï¸  HALLUCINATION DETECTED: LLM claimed booking success without calling book_appointment!")
                    # Override the hallucinated response
                    final_response = "Äá»ƒ hoÃ n táº¥t Ä‘áº·t lá»‹ch, tÃ´i cáº§n thá»±c hiá»‡n Ä‘áº·t lá»‹ch trong há»‡ thá»‘ng. Xin vui lÃ²ng xÃ¡c nháº­n láº¡i thÃ´ng tin: tÃªn, ngÃ y giá», lÃ½ do khÃ¡m vÃ  sá»‘ Ä‘iá»‡n thoáº¡i Ä‘á»ƒ tÃ´i Ä‘áº·t lá»‹ch cho báº¡n."
            
            state["final_response"] = final_response
            state["current_step"] += 1
        except Exception as e:
            print(f"âŒ AppointmentScheduler error: {str(e)}")
            import traceback
            traceback.print_exc()
            state["final_response"] = "Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ khi xá»­ lÃ½ yÃªu cáº§u Ä‘áº·t lá»‹ch cá»§a báº¡n. Vui lÃ²ng cung cáº¥p thÃ´ng tin: tÃªn, ngÃ y, giá», vÃ  lÃ½ do khÃ¡m."
        
        return state