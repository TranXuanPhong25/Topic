"""
Gemini Vision Analyzer for medical image analysis using Gemini 2.0 Flash Lite.

This module provides vision analysis capabilities using Google's Gemini 2.0 Flash Lite model,
which supports multimodal input (text + images) for analyzing medical images.
"""

import base64
from typing import Dict, Any, Optional
from PIL import Image
import io
from src.configs.agent_config import HumanMessage

class GeminiVisionAnalyzer:
    """
    Vision analyzer using Gemini 2.0 Flash Lite for medical image analysis.
    
    This class provides:
    - Image description and analysis
    - Visual Q&A based on symptoms
    - Medical image interpretation
    - Confidence scoring
    """
    
    def __init__(self, model):
       self.model = model
    
    def analyze_image(
        self, 
        image_data: str, 
        symptoms_text: str = ""
    ) -> Dict[str, Any]:
        """
        Analyze a medical image using Gemini Vision.
        
        Args:
            image_data: Base64 encoded image string
            symptoms_text: Optional text description of symptoms
        
        Returns:
            Dictionary containing:
            - visual_description: Detailed description of the image
            - visual_qa_results: Answers to symptom-specific questions
            - confidence: Confidence score (0-1)
            - error: Error message if any
        """        
        try:
            # Decode base64 image
            image = self._decode_base64_image(image_data)
            
            # Generate visual description
            visual_description = self._generate_visual_description(image)
            
            # Perform visual Q&A if symptoms provided
            visual_qa_results = {}
            if symptoms_text and symptoms_text.strip():
                visual_qa_results = self._perform_visual_qa(image, symptoms_text)
            
            # Calculate confidence based on response quality
            confidence = self._calculate_confidence(visual_description, visual_qa_results)
            
            result = {
                "visual_description": visual_description,
                "visual_qa_results": visual_qa_results,
                "confidence": confidence,
                "error": None
            }
            
            print(f"Vision analysis complete. Confidence: {confidence:.2f}")
            return result
            
        except Exception as e:
            print(f"Vision analysis error: {str(e)}")
            return {
                "visual_description": "",
                "visual_qa_results": {},
                "confidence": 0.0,
                "error": str(e)
            }
    
    def _decode_base64_image(self, image_data: str) -> Image.Image:
        """
        Decode base64 image string to PIL Image.
        
        Args:
            image_data: Base64 encoded image string
        
        Returns:
            PIL Image object
        """
        try:
            # Remove data URL prefix if present
            if ',' in image_data:
                image_data = image_data.split(',', 1)[1]
            
            # Decode base64
            image_bytes = base64.b64decode(image_data)
            
            # Convert to PIL Image
            image = Image.open(io.BytesIO(image_bytes))
            
            # Convert to RGB if needed
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            print(f"Decoded image: {image.size}, mode: {image.mode}")
            return image
            
        except Exception as e:
            print(f"Error decoding image: {str(e)}")
            raise ValueError(f"Invalid image data: {str(e)}")
    
    def _pil_image_to_base64(self, image: Image.Image) -> str:
        """
        Convert PIL Image to base64 string for LangChain vision input.
        
        Args:
            image: PIL Image object
        
        Returns:
            Base64 encoded image string
        """
        buffered = io.BytesIO()
        image.save(buffered, format="JPEG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return img_str
    
    def _generate_visual_description(self, image: Image.Image) -> str:
        """
        Generate a detailed description of the medical image using Gemini Vision.
        
        Args:
            image: PIL Image object
        
        Returns:
            Detailed visual description
        """
        prompt = """Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch hÃ¬nh áº£nh y táº¿. HÃ£y mÃ´ táº£ chi tiáº¿t nhá»¯ng gÃ¬ báº¡n tháº¥y trong hÃ¬nh áº£nh nÃ y.

                    **Nhiá»‡m vá»¥:**
                    Cung cáº¥p mÃ´ táº£ khÃ¡ch quan, chi tiáº¿t vá»:
                    1. Loáº¡i hÃ¬nh áº£nh (da, váº¿t thÆ°Æ¡ng, pháº§n cÆ¡ thá»ƒ, v.v.)
                    2. MÃ u sáº¯c vÃ  káº¿t cáº¥u quan sÃ¡t Ä‘Æ°á»£c
                    3. KÃ­ch thÆ°á»›c vÃ  vá»‹ trÃ­ (náº¿u cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh)
                    4. Báº¥t ká»³ Ä‘áº·c Ä‘iá»ƒm báº¥t thÆ°á»ng nÃ o
                    5. CÃ¡c chi tiáº¿t cÃ³ liÃªn quan Ä‘áº¿n y táº¿

                    **LÆ°u Ã½:**
                    - Chá»‰ mÃ´ táº£ nhá»¯ng gÃ¬ báº¡n tháº¥y, KHÃ”NG cháº©n Ä‘oÃ¡n
                    - Sá»­ dá»¥ng thuáº­t ngá»¯ y táº¿ khi thÃ­ch há»£p
                    - Viáº¿t báº±ng tiáº¿ng Viá»‡t, rÃµ rÃ ng vÃ  chÃ­nh xÃ¡c
                    - Khoáº£ng 4-6 cÃ¢u

                    **MÃ´ táº£ hÃ¬nh áº£nh:**"""
        
        try:
            # Generate content with image
            image_base64 = self._pil_image_to_base64(image)
            message = HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]
            )
            response = self.model.invoke([message])
            description = response.content.strip()
            
            print(f"Generated visual description: {description[:100]}...")
            return description
            
        except Exception as e:
            print(f"Error generating visual description: {str(e)}")
            return f"KhÃ´ng thá»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh: {str(e)}"
    
    def _perform_visual_qa(
        self, 
        image: Image.Image, 
        symptoms_text: str
    ) -> Dict[str, str]:
        """
        Perform visual question answering based on symptoms.
        
        Args:
            image: PIL Image object
            symptoms_text: Patient's symptom description
        
        Returns:
            Dictionary of questions and answers
        """
        # Generate relevant questions based on symptoms
        questions = self._generate_questions(symptoms_text)
        
        qa_results = {}
        
        for question in questions:
            prompt = f"""Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch hÃ¬nh áº£nh y táº¿. 

                        **Triá»‡u chá»©ng cá»§a bá»‡nh nhÃ¢n:** {symptoms_text}

                        **CÃ¢u há»i:** {question}

                        **Nhiá»‡m vá»¥:**
                        Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn nhá»¯ng gÃ¬ báº¡n tháº¥y trong hÃ¬nh áº£nh.
                        - Tráº£ lá»i ngáº¯n gá»n, trá»±c tiáº¿p (1-2 cÃ¢u)
                        - Chá»‰ dá»±a trÃªn hÃ¬nh áº£nh, khÃ´ng Ä‘Æ°a ra cháº©n Ä‘oÃ¡n
                        - Viáº¿t báº±ng tiáº¿ng Viá»‡t

                        **Tráº£ lá»i:**"""
                                    
            try:
                image_base64 = self._pil_image_to_base64(image)
                message = HumanMessage(
                    content=[
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                    ]
                )
                response = self.model.invoke([message])
                answer = response.content.strip()
                qa_results[question] = answer
                print(f"Q: {question[:50]}... A: {answer[:50]}...")
                
            except Exception as e:
                print(f"Error in visual QA: {str(e)}")
                qa_results[question] = f"KhÃ´ng thá»ƒ tráº£ lá»i: {str(e)}"
        
        return qa_results
    
    def _generate_questions(self, symptoms_text: str) -> list:
        """
        Generate relevant questions based on symptoms.
        
        Args:
            symptoms_text: Patient's symptom description
        
        Returns:
            List of relevant questions to ask about the image
        """
        # Default medical image questions
        default_questions = [
            "CÃ³ tháº¥y dáº¥u hiá»‡u sÆ°ng táº¥y khÃ´ng?",
            "MÃ u sáº¯c cÃ³ báº¥t thÆ°á»ng khÃ´ng?",
            "CÃ³ tháº¥y dáº¥u hiá»‡u nhiá»…m trÃ¹ng khÃ´ng?",
        ]
        
        # Keyword-based question generation
        questions = default_questions.copy()
        
        symptoms_lower = symptoms_text.lower()
        
        if any(word in symptoms_lower for word in ['Ä‘á»', 'Ä‘á»', 'sÆ°ng', 'phá»“ng']):
            questions.append("Má»©c Ä‘á»™ Ä‘á» vÃ  sÆ°ng nhÆ° tháº¿ nÃ o?")
        
        if any(word in symptoms_lower for word in ['Ä‘au', 'nhá»©c', 'Ä‘á»›n']):
            questions.append("CÃ³ dáº¥u hiá»‡u gÃ¬ cho tháº¥y nguyÃªn nhÃ¢n Ä‘au khÃ´ng?")
        
        if any(word in symptoms_lower for word in ['váº¿t', 'thÆ°Æ¡ng', 'rÃ¡ch', 'xÆ°á»›c']):
            questions.append("Váº¿t thÆ°Æ¡ng trÃ´ng cÃ³ sáº¡ch sáº½ khÃ´ng?")
        
        if any(word in symptoms_lower for word in ['phÃ¡t ban', 'máº©n', 'ná»•i']):
            questions.append("PhÃ¡t ban trÃ´ng nhÆ° tháº¿ nÃ o (mÃ u sáº¯c, hÃ¬nh dáº¡ng)?")
        
        # Limit to 5 questions max
        return questions[:5]
    
    def _calculate_confidence(
        self, 
        description: str, 
        qa_results: Dict[str, str]
    ) -> float:
        """
        Calculate confidence score based on analysis quality.
        
        Args:
            description: Visual description text
            qa_results: Q&A results dictionary
        
        Returns:
            Confidence score between 0 and 1
        """
        confidence = 0.0
        
        # Base confidence from description quality
        if description and len(description) > 50:
            confidence += 0.5
        elif description and len(description) > 20:
            confidence += 0.3
        
        # Add confidence from Q&A results
        if qa_results:
            successful_answers = sum(
                1 for answer in qa_results.values() 
                if answer and "KhÃ´ng thá»ƒ" not in answer
            )
            qa_confidence = (successful_answers / len(qa_results)) * 0.5
            confidence += qa_confidence
        
        # Check for error indicators
        if "khÃ´ng thá»ƒ" in description.lower() or "lá»—i" in description.lower():
            confidence *= 0.5
        
        return min(confidence, 1.0)
    
    def analyze_skin_condition(
        self, 
        image_data: str, 
        specific_concern: str = ""
    ) -> Dict[str, Any]:
        """
        Specialized analysis for skin conditions.
        
        Args:
            image_data: Base64 encoded image
            specific_concern: Specific skin concern (e.g., "rash", "lesion")
        
        Returns:
            Detailed skin analysis
        """
        try:
            image = self._decode_base64_image(image_data)
            
            concern_text = f" vá» {specific_concern}" if specific_concern else ""
            
            prompt = f"""Báº¡n lÃ  chuyÃªn gia da liá»…u phÃ¢n tÃ­ch hÃ¬nh áº£nh. HÃ£y phÃ¢n tÃ­ch tÃ¬nh tráº¡ng da trong hÃ¬nh áº£nh{concern_text}.

                        **Nhiá»‡m vá»¥:** Cung cáº¥p phÃ¢n tÃ­ch chi tiáº¿t vá»:
                        1. **Loáº¡i tá»•n thÆ°Æ¡ng:** MÃ´ táº£ loáº¡i tá»•n thÆ°Æ¡ng da (má»¥n, phÃ¡t ban, ná»‘t ruá»“i, v.v.)
                        2. **Äáº·c Ä‘iá»ƒm:** MÃ u sáº¯c, kÃ­ch thÆ°á»›c, hÃ¬nh dáº¡ng, ranh giá»›i
                        3. **PhÃ¢n bá»‘:** Khu trÃº hoáº·c lan rá»™ng, Ä‘á»‘i xá»©ng hay khÃ´ng
                        4. **CÃ¡c dáº¥u hiá»‡u:** SÆ°ng táº¥y, váº£y, tiáº¿t dá»‹ch, v.v.
                        5. **Má»©c Ä‘á»™ nghiÃªm trá»ng:** Nháº¹/Trung bÃ¬nh/Náº·ng

                        **LÆ°u Ã½:**
                        - MÃ´ táº£ khÃ¡ch quan, khÃ´ng cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c
                        - Sá»­ dá»¥ng thuáº­t ngá»¯ da liá»…u
                        - Viáº¿t báº±ng tiáº¿ng Viá»‡t
                        - Khoáº£ng 5-7 cÃ¢u

                        **PhÃ¢n tÃ­ch:**"""
                                    
            image_base64 = self._pil_image_to_base64(image)
            message = HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]
            )
            response = self.model.invoke([message])
            analysis = response.content.strip()
            
            return {
                "analysis": analysis,
                "type": "skin_condition",
                "confidence": 0.85 if len(analysis) > 100 else 0.6,
                "error": None
            }
            
        except Exception as e:
            print(f"Skin analysis error: {str(e)}")
            return {
                "analysis": "",
                "type": "skin_condition",
                "confidence": 0.0,
                "error": str(e)
            }
    
    def analyze_wound(
        self, 
        image_data: str
    ) -> Dict[str, Any]:
        """
        Specialized analysis for wound assessment.
        
        Args:
            image_data: Base64 encoded image
        
        Returns:
            Detailed wound analysis
        """
        try:
            image = self._decode_base64_image(image_data)
            
            prompt = """Báº¡n lÃ  chuyÃªn gia chÄƒm sÃ³c váº¿t thÆ°Æ¡ng phÃ¢n tÃ­ch hÃ¬nh áº£nh. HÃ£y Ä‘Ã¡nh giÃ¡ váº¿t thÆ°Æ¡ng trong hÃ¬nh áº£nh.

                        **Nhiá»‡m vá»¥:** PhÃ¢n tÃ­ch:
                        1. **Loáº¡i váº¿t thÆ°Æ¡ng:** Cáº¯t, xÆ°á»›c, bá»ng, v.v.
                        2. **KÃ­ch thÆ°á»›c vÃ  Ä‘á»™ sÃ¢u:** Æ¯á»›c tÃ­nh náº¿u cÃ³ thá»ƒ
                        3. **TÃ¬nh tráº¡ng:** Sáº¡ch/nhiá»…m trÃ¹ng, khÃ´/Æ°á»›t
                        4. **Dáº¥u hiá»‡u nhiá»…m trÃ¹ng:** Má»§, Ä‘á», sÆ°ng, nÃ³ng
                        5. **Giai Ä‘oáº¡n lÃ nh:** Má»›i/Ä‘ang lÃ nh/Ä‘Ã£ lÃ nh
                        6. **Cáº§n chÄƒm sÃ³c y táº¿:** CÃ³/KhÃ´ng vÃ  táº¡i sao

                        **LÆ°u Ã½:**
                        - ÄÃ¡nh giÃ¡ khÃ¡ch quan
                        - Táº­p trung vÃ o cÃ¡c dáº¥u hiá»‡u quan trá»ng
                        - Viáº¿t báº±ng tiáº¿ng Viá»‡t
                        - Khoáº£ng 6-8 cÃ¢u

                        **ÄÃ¡nh giÃ¡ váº¿t thÆ°Æ¡ng:**"""
            
            image_base64 = self._pil_image_to_base64(image)
            message = HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]
            )
            response = self.model.invoke([message])
            analysis = response.content.strip()
            
            return {
                "analysis": analysis,
                "type": "wound",
                "confidence": 0.85 if len(analysis) > 100 else 0.6,
                "error": None
            }
            
        except Exception as e:
            print(f"Wound analysis error: {str(e)}")
            return {
                "analysis": "",
                "type": "wound",
                "confidence": 0.0,
                "error": str(e)
            }

    def classify_image_type(
        self, 
        image_data: str, 
        user_input: str = ""
    ) -> Dict[str, Any]:
        """
        Classify the type of image and determine if it's for diagnostic purposes.
        
        Args:
            image_data: Base64 encoded image string
            user_input: User's text input for context
        
        Returns:
            Dictionary containing:
            - image_type: "medical", "document", "general", "unclear"
            - is_diagnostic: Whether the image is for medical diagnosis
            - intent: Detected user intent for the image
            - confidence: Classification confidence
        """
        try:
            image = self._decode_base64_image(image_data)
            
            context_hint = f"\n**Ngá»¯ cáº£nh tá»« ngÆ°á»i dÃ¹ng:** {user_input}" if user_input else ""
            
            prompt = f"""Báº¡n lÃ  chuyÃªn gia phÃ¢n loáº¡i hÃ¬nh áº£nh y táº¿. HÃ£y xÃ¡c Ä‘á»‹nh loáº¡i hÃ¬nh áº£nh.
{context_hint}

**QUAN TRá»ŒNG - PhÃ¢n loáº¡i hÃ¬nh áº£nh thÃ nh Má»˜T trong cÃ¡c loáº¡i sau:**

1. **document** - TÃ i liá»‡u y táº¿ bao gá»“m:
   - ÄÆ¡n thuá»‘c (cÃ³ tÃªn thuá»‘c, liá»u lÆ°á»£ng, hÆ°á»›ng dáº«n sá»­ dá»¥ng)
   - Káº¿t quáº£ xÃ©t nghiá»‡m (cÃ³ sá»‘ liá»‡u, chá»‰ sá»‘, giÃ¡ trá»‹)
   - Giáº¥y khÃ¡m bá»‡nh, phiáº¿u khÃ¡m
   - HÃ³a Ä‘Æ¡n y táº¿, biÃªn lai
   - Toa thuá»‘c viáº¿t tay hoáº·c in
   - Báº¥t ká»³ giáº¥y tá»/vÄƒn báº£n nÃ o liÃªn quan y táº¿
   - **Dáº¤U HIá»†U NHáº¬N BIáº¾T**: cÃ³ chá»¯ viáº¿t, báº£ng biá»ƒu, logo bá»‡nh viá»‡n/phÃ²ng khÃ¡m, format giáº¥y tá»

2. **medical** - áº¢nh y táº¿ Ä‘á»ƒ cháº©n Ä‘oÃ¡n:
   - áº¢nh da, váº¿t thÆ°Æ¡ng, phÃ¡t ban, má»¥n
   - VÃ¹ng cÆ¡ thá»ƒ bá»‹ Ä‘au, sÆ°ng, viÃªm
   - Triá»‡u chá»©ng nhÃ¬n tháº¥y Ä‘Æ°á»£c trÃªn cÆ¡ thá»ƒ
   - **Dáº¤U HIá»†U NHáº¬N BIáº¾T**: áº£nh chá»¥p trá»±c tiáº¿p cÆ¡ thá»ƒ ngÆ°á»i

3. **general** - áº¢nh chung khÃ´ng liÃªn quan y táº¿:
   - áº¢nh chÃ¢n dung, selfie bÃ¬nh thÆ°á»ng
   - Phong cáº£nh, Ä‘á»“ váº­t, thá»©c Äƒn
   - áº¢nh khÃ´ng liÃªn quan Ä‘áº¿n sá»©c khá»e

4. **unclear** - CHá»ˆ dÃ¹ng khi THá»°C Sá»° khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh

**âš ï¸ LÆ¯U Ã QUAN TRá»ŒNG:**
- Náº¿u tháº¥y CHá»® VIáº¾T hoáº·c FORMAT GIáº¤Y Tá»œ â†’ Æ°u tiÃªn phÃ¢n loáº¡i lÃ  **document**
- Náº¿u ngÆ°á»i dÃ¹ng há»i vá» "Ä‘Æ¡n thuá»‘c", "toa thuá»‘c", "káº¿t quáº£ xÃ©t nghiá»‡m" â†’ phÃ¢n loáº¡i lÃ  **document**
- TRÃNH phÃ¢n loáº¡i lÃ  "unclear" trá»« khi tháº­t sá»± khÃ´ng nhÃ¬n tháº¥y gÃ¬

**Tráº£ lá»i theo Ä‘á»‹nh dáº¡ng sau (CHÃNH XÃC):**
LOáº I: [medical/document/general/unclear]
CHáº¨N_ÄOÃN: [cÃ³/khÃ´ng]
Ã_Äá»ŠNH: [mÃ´ táº£ ngáº¯n gá»n má»¥c Ä‘Ã­ch cá»§a ngÆ°á»i dÃ¹ng khi gá»­i áº£nh]
Äá»˜_TIN_Cáº¬Y: [cao/trung bÃ¬nh/tháº¥p]

**PhÃ¢n loáº¡i:**"""
            
            print(f"ðŸ” Classifying image with user context: {user_input[:50] if user_input else 'None'}...")
            
            image_base64 = self._pil_image_to_base64(image)
            message = HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]
            )
            response = self.model.invoke([message])
            result_text = response.content.strip()
            
            print(f"ðŸ” Classification raw response: {result_text[:200]}...")
            
            # Parse the response
            image_type = "unclear"
            is_diagnostic = False
            intent = ""
            confidence = 0.5
            
            lines = result_text.split("\n")
            for line in lines:
                line_lower = line.lower().strip()
                if line_lower.startswith("loáº¡i:"):
                    type_value = line.split(":", 1)[1].strip().lower()
                    # Handle variations in response
                    if "document" in type_value or "tÃ i liá»‡u" in type_value:
                        image_type = "document"
                    elif "medical" in type_value or "y táº¿" in type_value:
                        image_type = "medical"
                    elif "general" in type_value or "chung" in type_value:
                        image_type = "general"
                    elif type_value in ["medical", "document", "general", "unclear"]:
                        image_type = type_value
                elif line_lower.startswith("cháº©n_Ä‘oÃ¡n:"):
                    diag_value = line.split(":", 1)[1].strip().lower()
                    is_diagnostic = diag_value in ["cÃ³", "yes", "true", "1"]
                elif line_lower.startswith("Ã½_Ä‘á»‹nh:"):
                    intent = line.split(":", 1)[1].strip()
                elif line_lower.startswith("Ä‘á»™_tin_cáº­y:"):
                    conf_value = line.split(":", 1)[1].strip().lower()
                    if conf_value == "cao" or "cao" in conf_value:
                        confidence = 0.9
                    elif conf_value == "trung bÃ¬nh" or "trung" in conf_value:
                        confidence = 0.7
                    else:
                        confidence = 0.5
            
            # Fallback: check for document keywords in response if still unclear
            if image_type == "unclear":
                result_lower = result_text.lower()
                if any(kw in result_lower for kw in ["Ä‘Æ¡n thuá»‘c", "toa thuá»‘c", "prescription", "káº¿t quáº£ xÃ©t nghiá»‡m", "test result", "giáº¥y khÃ¡m", "phiáº¿u khÃ¡m"]):
                    print("ðŸ” Fallback: Detected document keywords in response, changing type to document")
                    image_type = "document"
            
            # Force correct diagnostic status based on image type
            # Only medical images can be diagnostic
            if image_type == "medical":
                is_diagnostic = True
            elif image_type in ["document", "general"]:
                # Documents and general images are NOT for medical diagnosis
                is_diagnostic = False
            # For unclear, keep whatever LLM returned
            
            print(f"ðŸ” Image classification: type={image_type}, diagnostic={is_diagnostic}, confidence={confidence}")
            
            return {
                "image_type": image_type,
                "is_diagnostic": is_diagnostic,
                "intent": intent,
                "confidence": confidence,
                "raw_response": result_text
            }
            
        except Exception as e:
            print(f"Image classification error: {str(e)}")
            # Default to medical/diagnostic on error to be safe
            return {
                "image_type": "medical",
                "is_diagnostic": True,
                "intent": "KhÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh",
                "confidence": 0.3,
                "error": str(e)
            }

    def analyze_document(
        self, 
        image_data: str, 
        user_input: str = ""
    ) -> Dict[str, Any]:
        """
        Analyze a document image (prescription, test result, etc.)
        
        Args:
            image_data: Base64 encoded image string
            user_input: User's text input for context
        
        Returns:
            Dictionary containing document analysis results
        """
        try:
            image = self._decode_base64_image(image_data)
            
            context_hint = f"\n**YÃªu cáº§u tá»« ngÆ°á»i dÃ¹ng:** {user_input}" if user_input else ""
            
            prompt = f"""Báº¡n lÃ  chuyÃªn gia Ä‘á»c vÃ  trÃ­ch xuáº¥t thÃ´ng tin tá»« tÃ i liá»‡u y táº¿. HÃ£y phÃ¢n tÃ­ch CHI TIáº¾T hÃ¬nh áº£nh tÃ i liá»‡u nÃ y.
{context_hint}

**QUAN TRá»ŒNG - Nhiá»‡m vá»¥ cá»§a báº¡n:**
1. **XÃ¡c Ä‘á»‹nh loáº¡i tÃ i liá»‡u**: ÄÆ¡n thuá»‘c, káº¿t quáº£ xÃ©t nghiá»‡m, giáº¥y khÃ¡m bá»‡nh, hay loáº¡i khÃ¡c?

2. **Náº¿u lÃ  ÄÆ N THUá»C - TrÃ­ch xuáº¥t Tá»ªNG THUá»C vá»›i format sau:**
   - TÃªn thuá»‘c: [tÃªn Ä‘áº§y Ä‘á»§]
   - Liá»u lÆ°á»£ng: [sá»‘ lÆ°á»£ng, mg/ml náº¿u cÃ³]
   - CÃ¡ch dÃ¹ng: [ngÃ y máº¥y láº§n, uá»‘ng/bÃ´i/tiÃªm...]
   - Thá»i gian: [trÆ°á»›c/sau Äƒn, sÃ¡ng/trÆ°a/tá»‘i]
   - Sá»‘ lÆ°á»£ng: [bao nhiÃªu viÃªn/lá»/...]

3. **Náº¿u lÃ  Káº¾T QUáº¢ XÃ‰T NGHIá»†M - TrÃ­ch xuáº¥t tá»«ng chá»‰ sá»‘:**
   - TÃªn xÃ©t nghiá»‡m: [tÃªn]
   - Káº¿t quáº£: [giÃ¡ trá»‹]
   - ÄÆ¡n vá»‹: [Ä‘Æ¡n vá»‹ Ä‘o]
   - Pháº¡m vi bÃ¬nh thÆ°á»ng: [náº¿u cÃ³]

4. **ThÃ´ng tin bá»• sung:**
   - TÃªn bá»‡nh nhÃ¢n (náº¿u cÃ³)
   - TÃªn bÃ¡c sÄ©/cÆ¡ sá»Ÿ y táº¿ (náº¿u cÃ³)
   - NgÃ y kÃª Ä‘Æ¡n/xÃ©t nghiá»‡m (náº¿u cÃ³)
   - Cháº©n Ä‘oÃ¡n/ghi chÃº (náº¿u cÃ³)

**LÆ°u Ã½:**
- TrÃ­ch xuáº¥t Táº¤T Cáº¢ thÃ´ng tin cÃ³ thá»ƒ Ä‘á»c Ä‘Æ°á»£c
- Ghi rÃµ "[khÃ´ng Ä‘á»c Ä‘Æ°á»£c]" cho pháº§n má»/khÃ´ng rÃµ
- KHÃ”NG Ä‘Æ°a ra lá»i khuyÃªn y táº¿ hay cháº©n Ä‘oÃ¡n
- Viáº¿t CHI TIáº¾T vÃ  Cá»¤ THá»‚

**PhÃ¢n tÃ­ch tÃ i liá»‡u:**"""
            
            image_base64 = self._pil_image_to_base64(image)
            
            print(f"ðŸ“„ Sending document to LLM for analysis...")
            print(f"ðŸ“„ Image base64 length: {len(image_base64)} chars")
            
            message = HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]
            )
            
            try:
                response = self.model.invoke([message])
                print(f"ðŸ“„ Raw response type: {type(response)}")
                print(f"ðŸ“„ Raw response: {response}")
                
                if hasattr(response, 'content'):
                    content = response.content.strip() if response.content else ""
                else:
                    content = str(response).strip()
                    
            except Exception as invoke_error:
                print(f"âŒ LLM invoke error: {invoke_error}")
                import traceback
                traceback.print_exc()
                content = ""
            
            print(f"ðŸ“„ Document analysis response length: {len(content)} chars")
            if content:
                print(f"ðŸ“„ Document analysis preview: {content[:300]}...")
            else:
                print("âš ï¸ Document analysis returned empty content!")
            
            # Try to detect document type from response
            doc_type = "unknown"
            content_lower = content.lower()
            if "Ä‘Æ¡n thuá»‘c" in content_lower or "prescription" in content_lower:
                doc_type = "prescription"
            elif "xÃ©t nghiá»‡m" in content_lower or "káº¿t quáº£" in content_lower or "test" in content_lower:
                doc_type = "test_result"
            elif "giáº¥y khÃ¡m" in content_lower or "phiáº¿u khÃ¡m" in content_lower:
                doc_type = "medical_record"
            elif "hÃ³a Ä‘Æ¡n" in content_lower:
                doc_type = "invoice"
            
            return {
                "description": "PhÃ¢n tÃ­ch tÃ i liá»‡u y táº¿",
                "content": content,
                "type": doc_type,
                "confidence": 0.8 if len(content) > 100 else 0.5,
                "error": None
            }
            
        except Exception as e:
            print(f"Document analysis error: {str(e)}")
            return {
                "description": "",
                "content": "",
                "type": "unknown",
                "confidence": 0.0,
                "error": str(e)
            }