"""
LEVEL 1: Simple Guardrail
- Keyword-based detection
- Basic input/output validation
- Emergency detection
- Profanity filtering
- Quick and lightweight
"""

import re
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class GuardrailResult:
    """Result of guardrail check"""
    passed: bool
    reason: Optional[str] = None
    action: Optional[str] = None  # "block", "warn", "redirect", "allow"
    modified_content: Optional[str] = None
    severity: str = "info"  # "info", "warning", "critical"


class SimpleGuardrail:
    """
    Simple keyword-based guardrail system.
    Fast, deterministic, easy to maintain.
    """
    
    # Emergency keywords (multiple languages)
    EMERGENCY_KEYWORDS = [
        # Vietnamese
        "cáº¥p cá»©u", "kháº©n cáº¥p", "nguy ká»‹ch", "hÃ´n mÃª", "Ä‘au tim", 
        "Ä‘á»™t quá»µ", "khÃ´ng thá»Ÿ", "cháº£y mÃ¡u nhiá»u", "tai náº¡n",
        "ngá»™ Ä‘á»™c", "tá»± tá»­", "tá»± sÃ¡t", "muá»‘n cháº¿t",
        # English
        "emergency", "911", "dying", "heart attack", "stroke",
        "suicide", "can't breathe", "severe bleeding", "unconscious"
    ]
    
    # Medical advice keywords (bot should NOT give)
    MEDICAL_ADVICE_KEYWORDS = [
        "cháº©n Ä‘oÃ¡n", "kÃª Ä‘Æ¡n", "thuá»‘c gÃ¬", "liá»u lÆ°á»£ng thuá»‘c",
        "diagnose", "prescription", "what medicine", "drug dosage",
        "cÃ³ pháº£i bá»‡nh", "bá»‡nh gÃ¬", "cÃ³ bá»‹ ung thÆ°",
        "is it cancer", "what disease"
    ]
    
    # Personal/sensitive data keywords
    SENSITIVE_DATA_KEYWORDS = [
        "sá»‘ cmnd", "cccd", "tháº» tÃ­n dá»¥ng", "máº­t kháº©u", "password",
        "credit card", "social security", "bank account",
        "tÃ i khoáº£n ngÃ¢n hÃ ng"
    ]
    
    # Inappropriate content
    PROFANITY_KEYWORDS = [
        "Ä‘á»“ chÃ³", "Ä‘á»‹t", "lá»“n", "fuck", "shit", "damn",
        "ngu", "khá»‘n", "cháº¿t tiá»‡t"
    ]
    
    # Scope violations (out of domain)
    OUT_OF_SCOPE_KEYWORDS = [
        "thá»i tiáº¿t", "bÃ³ng Ä‘Ã¡", "chÃ­nh trá»‹", "tÃ´n giÃ¡o",
        "weather", "football", "politics", "religion",
        "náº¥u Äƒn", "cooking", "du lá»‹ch", "travel"
    ]
    
    def __init__(self):
        """Initialize simple guardrail"""
        self.blocked_count = 0
        self.warned_count = 0
        
    def check_input(self, user_input: str) -> GuardrailResult:
        """
        Check user input before processing
        
        Args:
            user_input: Raw user message
            
        Returns:
            GuardrailResult with pass/fail and action
        """
        user_input_lower = user_input.lower()
        
        # 1. Check for emergencies (highest priority)
        if self._contains_keywords(user_input_lower, self.EMERGENCY_KEYWORDS):
            return GuardrailResult(
                passed=True,  # Allow but redirect
                reason="Emergency detected",
                action="redirect",
                modified_content="ğŸš¨ KHáº¨N Cáº¤P: Vui lÃ²ng Gá»ŒI 115 hoáº·c Ä‘áº¿n bá»‡nh viá»‡n gáº§n nháº¥t ngay láº­p tá»©c!",
                severity="critical"
            )
        
        # 2. Check for profanity
        if self._contains_keywords(user_input_lower, self.PROFANITY_KEYWORDS):
            self.blocked_count += 1
            return GuardrailResult(
                passed=False,
                reason="Inappropriate language detected",
                action="block",
                modified_content="Xin lá»—i, tÃ´i khÃ´ng thá»ƒ xá»­ lÃ½ tin nháº¯n chá»©a ngÃ´n tá»« khÃ´ng phÃ¹ há»£p.",
                severity="warning"
            )
        
        # 3. Check for sensitive data (PII protection)
        if self._contains_keywords(user_input_lower, self.SENSITIVE_DATA_KEYWORDS):
            self.warned_count += 1
            return GuardrailResult(
                passed=True,
                reason="Potential sensitive data detected",
                action="warn",
                modified_content=None,  # Allow but log warning
                severity="warning"
            )
        
        # 4. Check for out-of-scope requests
        if self._contains_keywords(user_input_lower, self.OUT_OF_SCOPE_KEYWORDS):
            return GuardrailResult(
                passed=False,
                reason="Out of scope request",
                action="block",
                modified_content="Xin lá»—i, tÃ´i chá»‰ cÃ³ thá»ƒ há»— trá»£ vá» cÃ¡c váº¥n Ä‘á» y táº¿ vÃ  phÃ²ng khÃ¡m. TÃ´i khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y.",
                severity="info"
            )
        
        # 5. Input length validation
        if len(user_input) > 2000:
            return GuardrailResult(
                passed=False,
                reason="Input too long",
                action="block",
                modified_content="Tin nháº¯n quÃ¡ dÃ i. Vui lÃ²ng rÃºt gá»n láº¡i (tá»‘i Ä‘a 2000 kÃ½ tá»±).",
                severity="info"
            )
        
        if len(user_input.strip()) < 2:
            return GuardrailResult(
                passed=False,
                reason="Input too short",
                action="block",
                modified_content="Vui lÃ²ng nháº­p tin nháº¯n cÃ³ ná»™i dung.",
                severity="info"
            )
        
        # All checks passed
        return GuardrailResult(
            passed=True,
            reason="Input validation passed",
            action="allow",
            severity="info"
        )
    
    def check_output(self, bot_response: str, user_input: str) -> GuardrailResult:
        """
        Check bot output before sending to user
        
        Args:
            bot_response: Generated bot response
            user_input: Original user input for context
            
        Returns:
            GuardrailResult with pass/fail and action
        """
        response_lower = bot_response.lower()
        
        # 1. Check if bot is giving medical advice (forbidden)
        medical_advice_patterns = [
            r"báº¡n (cÃ³ thá»ƒ|nÃªn) uá»‘ng thuá»‘c",
            r"Ä‘Ã¢y lÃ  bá»‡nh",
            r"cháº©n Ä‘oÃ¡n cá»§a báº¡n lÃ ",
            r"you (have|might have)",
            r"(take|use) this (medicine|drug)",
            r"diagnosis is"
        ]
        
        for pattern in medical_advice_patterns:
            if re.search(pattern, response_lower):
                return GuardrailResult(
                    passed=False,
                    reason="Bot attempting to give medical advice",
                    action="block",
                    modified_content="Xin lá»—i, tÃ´i khÃ´ng thá»ƒ Ä‘Æ°a ra cháº©n Ä‘oÃ¡n hoáº·c kÃª Ä‘Æ¡n thuá»‘c. Vui lÃ²ng Ä‘áº·t lá»‹ch khÃ¡m vá»›i bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chuyÃªn mÃ´n.",
                    severity="critical"
                )
        
        # 2. Check response length (too short might be error)
        if len(bot_response.strip()) < 10:
            return GuardrailResult(
                passed=False,
                reason="Response too short (possible error)",
                action="block",
                modified_content="Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ khi táº¡o pháº£n há»“i. Vui lÃ²ng thá»­ láº¡i.",
                severity="warning"
            )
        
        # 3. Check for leaked system prompts or technical errors
        system_leakage_keywords = [
            "system:", "assistant:", "you are a", "báº¡n lÃ  má»™t ai",
            "prompt:", "instruction:", "error:", "exception:",
            "traceback", "api_key", "token"
        ]
        
        if self._contains_keywords(response_lower, system_leakage_keywords):
            return GuardrailResult(
                passed=False,
                reason="System information leakage detected",
                action="block",
                modified_content="Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra. Vui lÃ²ng thá»­ láº¡i hoáº·c liÃªn há»‡ bá»™ pháº­n há»— trá»£.",
                severity="critical"
            )
        
        # 4. Check for contact info disclosure (protect staff privacy)
        contact_patterns = [
            r'\b\d{10,11}\b',  # Phone numbers
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',  # Emails
            r'\b\d{4}\s*\d{4}\s*\d{4}\s*\d{4}\b'  # Credit card pattern
        ]
        
        for pattern in contact_patterns:
            if re.search(pattern, bot_response):
                # Allow official clinic contact only
                if "clinic" in user_input.lower() or "phÃ²ng khÃ¡m" in user_input.lower():
                    continue
                
                return GuardrailResult(
                    passed=False,
                    reason="Unauthorized contact information disclosure",
                    action="warn",
                    modified_content=None,
                    severity="warning"
                )
        
        # All checks passed
        return GuardrailResult(
            passed=True,
            reason="Output validation passed",
            action="allow",
            severity="info"
        )
    
    def _contains_keywords(self, text: str, keywords: List[str]) -> bool:
        """Check if text contains any of the keywords"""
        return any(keyword.lower() in text for keyword in keywords)
    
    def get_stats(self) -> Dict:
        """Get guardrail statistics"""
        return {
            "type": "simple",
            "blocked_count": self.blocked_count,
            "warned_count": self.warned_count
        }


# Example usage
if __name__ == "__main__":
    guardrail = SimpleGuardrail()
    
    # Test cases
    test_inputs = [
        "TÃ´i bá»‹ Ä‘au tim, cáº§n cáº¥p cá»©u!",  # Emergency
        "Äá»‹t máº¹ chatbot",  # Profanity
        "Sá»‘ CMND cá»§a tÃ´i lÃ  123456789",  # Sensitive data
        "Thá»i tiáº¿t hÃ´m nay tháº¿ nÃ o?",  # Out of scope
        "TÃ´i cáº§n Ä‘áº·t lá»‹ch khÃ¡m",  # Normal
    ]
    
    for inp in test_inputs:
        result = guardrail.check_input(inp)
        print(f"\nInput: {inp}")
        print(f"Result: {result}")
