# ğŸ›¡ï¸ Guardrails System

3-level safety system for medical chatbot: Simple â†’ Intermediate â†’ Advanced

## Quick Start

### Level 1: Simple (Keyword-Based)
```python
from src.guardrails import SimpleGuardrail

guardrail = SimpleGuardrail()
result = guardrail.check_input("TÃ´i bá»‹ Ä‘au tim!")

if result.action == "redirect":
    print(result.modified_content)  # "ğŸš¨ Gá»i 115!"
```

**Features**: Emergency detection, profanity filter, PII detection, out-of-scope blocking  
**Speed**: < 1ms | **Cost**: Free | **Accuracy**: 70-80%

### Level 2: Intermediate (NLP + Context)
```python
from src.guardrails import IntermediateGuardrail

guardrail = IntermediateGuardrail(gemini_api_key="your-key")
result = guardrail.check_input(
    "TÃ´i cáº§n thuá»‘c gÃ¬?",
    user_id="user123",
    conversation_history=[...]
)

print(f"Intent: {result.reason}")
print(f"Confidence: {result.confidence}")
```

**Features**: Intent classification (Gemini), context-aware, rate limiting, medical claim verification  
**Speed**: 50-100ms | **Cost**: ~$5-10/month (1M msgs) | **Accuracy**: 85-90%

### Level 3: Advanced (Multi-Layer + Compliance)
```python
from src.guardrails import AdvancedGuardrail

guardrail = AdvancedGuardrail(gemini_api_key="your-key")
result = guardrail.check_input(
    "Sá»‘ Ä‘iá»‡n thoáº¡i: 0912345678",
    user_id="user456",
    conversation_history=[...]
)

print(f"Risk: {result.risk_level}")
print(f"Compliance: {result.compliance_violations}")
print(f"Scores: {result.safety_scores}")

# Export compliance report
report = guardrail.export_compliance_report()
```

**Features**: 5-layer validation, HIPAA/GDPR, adversarial detection, risk profiling, quality assessment  
**Speed**: 300-500ms | **Cost**: ~$30-50/month | **Accuracy**: 95-98%

## Integration

```python
# main.py
from src.guardrails import GuardrailManager

manager = GuardrailManager(level="intermediate")

@app.post("/chat")
async def chat(request: ChatRequest):
    # 1. Validate input
    validation = manager.validate_input(request.message, request.user_id)
    if not validation["passed"]:
        return {"response": validation["modified_content"]}
    
    # 2. Process
    response = await chatbot.process(request.message)
    
    # 3. Validate output
    output = manager.validate_output(response, request.message)
    return {"response": output["modified_content"] or response}
```

## Testing

```bash
# Run simple example
python -m src.guardrails.simple_guardrail

# Run all examples
python -m src.guardrails.integration_example

# Run tests
pytest tests/test_guardrails.py -v
```

## Comparison

| Level | Speed | Cost | Use Case |
|-------|-------|------|----------|
| Simple | < 1ms | Free | Prototype, MVP |
| Intermediate | ~80ms | Low | Production |
| Advanced | ~350ms | Medium | Enterprise, Medical |

## Documentation

Full documentation: [`/docs/GUARDRAILS.md`](/docs/GUARDRAILS.md)

## Files

```
src/guardrails/
â”œâ”€â”€ __init__.py                  # Exports
â”œâ”€â”€ simple_guardrail.py          # Level 1
â”œâ”€â”€ intermediate_guardrail.py    # Level 2
â”œâ”€â”€ advanced_guardrail.py        # Level 3
â””â”€â”€ integration_example.py       # Usage examples
```
