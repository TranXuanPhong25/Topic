# Gemini Vision Agent for Medical Image Analysis

This module implements a vision analysis agent using **Google Gemini 2.0 Flash Lite** for medical image analysis tasks. It provides intelligent image understanding capabilities for medical clinic chatbots.

## Features

### üéØ Core Capabilities
- **Visual Description Generation**: Detailed, medical-focused image descriptions
- **Visual Question Answering**: Context-aware Q&A based on patient symptoms
- **Skin Condition Analysis**: Specialized dermatology assessments
- **Wound Assessment**: Detailed wound evaluation and infection detection
- **Confidence Scoring**: Automatic quality assessment of analysis results

### ü§ñ Multi-Agent Integration
The vision agent integrates seamlessly with the LangGraph multi-agent workflow:
1. **Vision Agent** ‚Üí Analyzes medical images
2. **Symptom Matcher** ‚Üí Correlates visual findings with text symptoms
3. **Risk Assessor** ‚Üí Determines urgency level
4. **Recommender** ‚Üí Provides actionable next steps

## Technology

### Why Gemini 2.0 Flash Lite?
- ‚úÖ **Multimodal**: Native support for image + text input
- ‚úÖ **Fast**: Optimized for quick responses
- ‚úÖ **Free Tier**: Generous free quota for learning projects
- ‚úÖ **High Quality**: State-of-the-art vision understanding
- ‚úÖ **Simple API**: Easy to integrate and use

### Model Configuration
```python
model_name = "gemini-2.0-flash-lite"
temperature = 0.4  # Balanced creativity and consistency
max_output_tokens = 2048
```

## Installation

### Dependencies
```bash
pip install google-generativeai Pillow
```

### API Key Setup
```bash
# Add to .env file
GOOGLE_API_KEY=your_google_api_key_here
```

Get your API key from: https://makersuite.google.com/app/apikey

## Usage

### Basic Image Analysis
```python
from src.vision.gemini_vision_analyzer import GeminiVisionAnalyzer

# Initialize
analyzer = GeminiVisionAnalyzer(google_api_key="your-key")

# Analyze image with symptoms
result = analyzer.analyze_image(
    image_data=base64_image,
    symptoms_text="T√¥i c√≥ v·∫øt ƒë·ªè tr√™n da, h∆°i s∆∞ng v√† ng·ª©a"
)

# Access results
print(result["visual_description"])
print(result["visual_qa_results"])
print(f"Confidence: {result['confidence']}")
```

### Specialized Analyses

#### Skin Condition Analysis
```python
result = analyzer.analyze_skin_condition(
    image_data=base64_image,
    specific_concern="ph√°t ban"  # rash
)

print(result["analysis"])
# Output: Detailed dermatological assessment
```

#### Wound Assessment
```python
result = analyzer.analyze_wound(image_data=base64_image)

print(result["analysis"])
# Output: Wound type, size, infection signs, care recommendations
```

### Multi-Agent Workflow
```python
from src.agents.medical_agent_graph import MedicalAgentGraph

# Initialize multi-agent system
agent_graph = MedicalAgentGraph(google_api_key="your-key")

# Run complete analysis
result = agent_graph.analyze(
    image_data=base64_image,
    symptoms_text="T√¥i b·ªã ƒëau v√† s∆∞ng ·ªü v√πng n√†y kho·∫£ng 2 ng√†y"
)

# Access comprehensive results
print(result["visual_analysis"])      # Vision agent output
print(result["medical_assessment"])    # Symptom matcher output
print(result["risk_level"])            # Risk assessor output
print(result["recommendations"])       # Recommender output
print(result["workflow_messages"])     # Complete workflow log
```

## Architecture

### GeminiVisionAnalyzer Class

#### Methods
- `analyze_image(image_data, symptoms_text)` - General medical image analysis
- `analyze_skin_condition(image_data, specific_concern)` - Dermatology focus
- `analyze_wound(image_data)` - Wound care focus

#### Internal Methods
- `_decode_base64_image()` - Convert base64 to PIL Image
- `_generate_visual_description()` - Create detailed image description
- `_perform_visual_qa()` - Answer symptom-specific questions
- `_generate_questions()` - Generate relevant questions based on symptoms
- `_calculate_confidence()` - Score analysis quality

### Data Flow
```
Base64 Image ‚Üí PIL Image ‚Üí Gemini Vision API ‚Üí Analysis Results
     ‚Üì
Symptoms Text ‚Üí Question Generation ‚Üí Visual Q&A ‚Üí Q&A Results
     ‚Üì
Combined Analysis ‚Üí Confidence Score ‚Üí Return to User
```

## Example Output

### Visual Description
```
"H√¨nh ·∫£nh cho th·∫•y m·ªôt v√πng da ·ªü c√°nh tay v·ªõi v·∫øt ƒë·ªè k√≠ch th∆∞·ªõc kho·∫£ng 3-4cm. 
V√πng n√†y c√≥ m√†u ƒë·ªè h·ªìng, h∆°i s∆∞ng n·ªïi so v·ªõi da xung quanh. B·ªÅ m·∫∑t da tr√¥ng kh√¥, 
kh√¥ng th·∫•y d·∫•u hi·ªáu ti·∫øt d·ªãch ho·∫∑c v·∫£y r√µ r·ªát. Ranh gi·ªõi c·ªßa v√πng ƒë·ªè t∆∞∆°ng ƒë·ªëi 
r√µ r√†ng. Kh√¥ng quan s√°t th·∫•y v·∫øt th∆∞∆°ng h·ªü ho·∫∑c d·∫•u hi·ªáu nhi·ªÖm tr√πng nghi√™m tr·ªçng."
```

### Visual Q&A Results
```python
{
    "C√≥ th·∫•y d·∫•u hi·ªáu s∆∞ng t·∫•y kh√¥ng?": 
        "C√≥, v√πng da c√≥ s∆∞ng nh·∫π, n·ªïi cao h∆°n da xung quanh kho·∫£ng 2-3mm.",
    
    "M√†u s·∫Øc c√≥ b·∫•t th∆∞·ªùng kh√¥ng?": 
        "C√≥ m√†u ƒë·ªè h·ªìng b·∫•t th∆∞·ªùng, kh√°c v·ªõi m√†u da b√¨nh th∆∞·ªùng xung quanh.",
    
    "C√≥ th·∫•y d·∫•u hi·ªáu nhi·ªÖm tr√πng kh√¥ng?": 
        "Kh√¥ng th·∫•y d·∫•u hi·ªáu nhi·ªÖm tr√πng r√µ r·ªát nh∆∞ m·ªß ho·∫∑c ti·∫øt d·ªãch."
}
```

### Confidence Score
- `0.8-1.0`: High confidence, detailed analysis
- `0.5-0.8`: Medium confidence, reasonable analysis
- `0.0-0.5`: Low confidence, limited information

## Best Practices

### Image Quality
- ‚úÖ Clear, well-lit photos
- ‚úÖ Close-up of affected area
- ‚úÖ In focus, not blurry
- ‚úÖ Good contrast
- ‚ùå Too dark or overexposed
- ‚ùå Too far away
- ‚ùå Obstructed view

### Symptom Descriptions
Provide context for better Q&A:
- Duration: "3 ng√†y nay"
- Symptoms: "ƒëau, s∆∞ng, ng·ª©a"
- Changes: "ng√†y c√†ng t·ªá h∆°n"
- Other: "sau khi b·ªã c√†o"

### Error Handling
```python
result = analyzer.analyze_image(image_data, symptoms)

if result["error"]:
    print(f"Analysis failed: {result['error']}")
else:
    # Process successful result
    pass
```

## Testing

Run the example file:
```bash
python examples/vision_agent_example.py
```

Run unit tests:
```bash
pytest tests/test_vision_analyzer.py -v
```

## Limitations

### Educational Project Notice
‚ö†Ô∏è **This is an educational project for learning chatbot development.**

For production medical use, add:
- HIPAA compliance
- Security audits
- Professional medical review
- Regulatory approvals
- Liability insurance

### Medical Disclaimers
- ‚ùå Not a substitute for professional medical advice
- ‚ùå Not for emergency situations (call 911)
- ‚ùå Analysis is descriptive, not diagnostic
- ‚úÖ Helps with appointment scheduling
- ‚úÖ Provides general information
- ‚úÖ Assists with triage

## Advanced Features

### Custom Prompts
Modify prompts in `GeminiVisionAnalyzer` for:
- Different languages
- Specific medical specialties
- Custom question sets
- Different output formats

### Integration Points
- **FastAPI endpoints**: Add vision analysis to chat API
- **Database storage**: Save analysis results
- **Todo system**: Create follow-up tasks based on findings
- **Appointment scheduling**: Auto-schedule based on risk level

## Troubleshooting

### Common Issues

**API Key Error**
```
Error: GOOGLE_API_KEY not found
Solution: Set environment variable or add to .env
```

**Image Decode Error**
```
Error: Invalid image data
Solution: Ensure base64 string is properly formatted
```

**Low Confidence Score**
```
Confidence < 0.5
Solution: Check image quality, provide more symptom context
```

## Contributing

### Adding New Analysis Types
1. Create new method in `GeminiVisionAnalyzer`
2. Design specialized prompt
3. Add to examples
4. Write tests

### Improving Prompts
- Test with various images
- Collect feedback
- Iterate on Vietnamese phrasing
- Add medical terminology

## Resources

- [Gemini API Documentation](https://ai.google.dev/docs)
- [LangGraph Documentation](https://python.langchain.com/docs/langgraph)
- [Project Quick Start](../QUICK_START.md)
- [Main README](../README.md)

## License

Educational use only. See project LICENSE for details.

## Contact

For questions about vision agent implementation:
- Check examples in `examples/vision_agent_example.py`
- Review code in `src/vision/gemini_vision_analyzer.py`
- See multi-agent workflow in `src/agents/medical_agent_graph.py`
